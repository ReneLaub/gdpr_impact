[["index.html", "The Impact of the General Data Protection Regulation (GDPR) on the Online Advertising Market Overview", " The Impact of the General Data Protection Regulation (GDPR) on the Online Advertising Market Bernd Skiera, Klaus Miller, Yuxi Jin, Lennart Kraft, Rene Laub, Julia Schmitt 2022-01-17 Overview This website contains the online version of the book The Impact of the General Data Protection Regulation (GDPR) on the Online Advertising Market written by Bernd Skiera, Klaus Miller, Yuxi Jin, Lennar Kraft, René Laub and Julia Schmitt. What will you learn from this book? Why and how the European General Data Protection Regulation (GDPR) impacts the online advertising market, particularly advertisers, publishers and users. How advertisers and publishers leverage users personal data to pursue their goals. Which aspects of the GDPR are most relevant for advertisers, publishers and users. How complex it is to go through the process of obtaining user permission for personal data processing, and how IABs Transparency and Consent Framework (TCF) intends to help. How many firms a publisher provides with access to its users data, and how long it takes a user to respond to all permission requests. Which developments are taking place with regard to personal data processing, among players in the online advertising industry, as well as among regulators and consumer protection agencies. Who should read this book? Anyone interested in learning how and why the online advertising industry benefits from using personal data, and how the GDPR impacts this practice. Who wrote this book? The European Research Council provided Professor Skiera at Goethe University Frankfurt (Germany) with a substantial (ERC Advanced) research grant to examine the economic consequences of stronger restrictions on tracking technologies. Professor Skiera and his team pursued several empirical projects to demonstrate these consequences. "],["introduction.html", "Section 1 Introduction", " Section 1 Introduction Tracking technologies such as cookies and digital fingerprinting enable firms to collect and exchange extensive data about consumers (users). These data are often used to improve the performance of online advertising, which publishershere defined as websites or apps that provide space to display adsrely on to finance the free content to which their users have become accustomed. Until recently, such data collection was massive in scope, and often occurred without users permission, which led to a loss of user privacy. In response, policymakers in Europe and elsewhere have put forward initiatives to protect user privacy. One of the most prominent regulations is Europes General Data Protection Regulation (GDPR), which went into effect in 2018; this regulation is at the focus of the current book. The GDPR will be complemented by the ePrivacy Regulation (ePR). Outside Europe, large-scale initiatives to protect user privacy include the California Consumer Privacy Act (CCPA), Indias Personal Data Protection Law (PDPB), Thailands Personal Data Protection Act (PDPA), Brazils Lei Geral de Proteção de Dados Pessoais (LGPD) and Chinas Personal Information Protection Law (PIPL). These laws prevent firms from processing personal data, where the term processing encompasses a wide range of operations, including collecting, combining and storing personal data. The main purpose of these laws is to protect users privacy. In fact, comprehensive reviews of privacy literature emphasize that there is no widely agreed-upon definition of privacy (Bleier, Goldfarb, and Tucker (2020), Martin and Murphy (2017), Norberg, Horne, and Horne (2007) and Wieringa et al. 2021). Westin (1967) defined privacy as the ability of the individual to control the terms under which personal information is acquired and used. The GDPR effectively relies on this conceptualization of privacy, as its main provisions focus on users control over their personal data. Herein, we adopt a similar perspective of the construct of privacywith some extensions. For example, in line with a common approach in the popular media, we assume that a more extensive collection of data from consumers implies less privacy. In restricting the processing of personal data, privacy laws affect online advertising and, thus, the different actors operating in the online advertising market. Though several studies have begun to explore these effects (e.g., Peukert et al. 2022; Schmitt, Miller, and Skiera 2021), researchers and policymakers have yet to obtain a comprehensive and precise understanding of the implications of privacy laws for the online advertising market. This lack of clarity is unfortunate because as regulations continue to be formulated or updated, it is crucial for regulators and societies at large to understand the trade-off between user privacy and the economic value that the online advertising industry derives from processing personal data through potentially privacy-infringing technologies. Likewise, firms in the online advertising industry need to understand the implications of stricter privacy requirements for their performance, so as to adjust to these requirements effectively. Finally, users also deserve to understand what happens with their data, and the consequences of such data usage, or restrictions thereof. One important reason for the lack of clarity on the implications of privacy laws for advertising is that the online advertising market is difficult to understand. It is a high-tech industry that comprises several extensive networks with many actors, as we will illustrate in these pages (see, in particular, our illustration of the complexity of the industry in Section 2 and our empirical study in Section 8). From a technological perspective, these actors accomplish extraordinary feats, such as conducting billions of auctions with many participants each day to sell single ad impressions in less than 100 milliseconds, or displaying personalized ads to millions of users. Because of the complex technologies used in online advertising, effective decision-making in this market requires combining a technological perspective (e.g., finding the best technology to track users) with a marketing perspective (e.g., finding the best users to target). With the launch of far-reaching privacy laws such as the GDPR, it is becoming increasingly important for actors in this industry to consider the legal perspective as well. The need to combine these three perspectives implies that professionals in the advertising field must possess some level of expertise in multiple domains. For example, lawyers in the advertising industry need to understand what cookies and consent strings are, and marketing managers and IT experts need to understand the meanings of legal terms such as legitimate interest or identifiable individual. Our vision for this book is, thus, to provide an accessible yet comprehensive synthesis of what is currently known about how privacy lawsparticularly the GDPRaffect the online advertising market. To this end, we highlight the requirements stipulated in the GDPR that are most relevant to the advertising industry, and we further clarify the implications of these requirements for the key actors in this industry, as well as for users. In doing so, we aim to provide actors in this market (in particular advertisers, publishers and users), as well as regulators and society at large, with better tools to (i) assess the trade-off between the benefits and the costs of more privacy, (ii) understand problems in implementing the requirements of GDPR, and (iii) draw conclusions on how to deal with the stricter privacy requirements that come with privacy laws such as the GDPR. The remainder of this book is organized as follows. Section 2 outlines how the online advertising industry operates. Section 3 provides a basic overview of tracking technologies, the ways in which publishers, advertisers, and other firms use them, and the implications of tracking for users. Section 4 elaborates on the contents of the GDPR, focusing on the obligations relevant to firms in the advertising industry. In Section 5, we discuss the GDPR requirement that affects the advertising industry most profoundly: the need to secure a legal basis for data processing, which, in practice, entails obtaining user permission for data processing for specific purposese.g., via consent management tools, discussed in Section 6. Section 7 provides a step-by-step description of the procedure that firms must undertake to obtain user permission for data processing, and it presents a framework developed by IAB Europe, Europes industry association for digital marketing and advertising, to assist firms in accomplishing this process (the Transparency and Consent Framework; TCF). Section 8 provides an empirical assessment of the complexity that firms face in obtaining permission, as well as the complexity that users face in handling permission requests. Section 9 provides an outlook on future developments in the advertising industry and in the regulatory landscape with regard to the processing of users personal data. Finally, Section 10 provides conclusions. "],["overview-of-the-online-advertising-industry.html", "Section 2 Overview of the Online Advertising Industry 2.1 Essential Actors: Advertisers, Publishers and Users 2.2 Scope and Types of Online Advertising 2.3 Real-Time Bidding as a Process of Selling Online Advertising 2.4 Description of Other Actors 2.5 Main Takeaways", " Section 2 Overview of the Online Advertising Industry 2.1 Essential Actors: Advertisers, Publishers and Users Online advertising is, in basic terms, a process in which an advertiser pays a publisher to present an ad to a user on the publishers property (usually a website or an app). Thus, there are three essential actors in online advertising (in alphabetical order): the advertiser, who wishes to draw the users interest to the advertisers offerings; the publisher, who has some space to show ads and would like to monetize the user by selling those ad spaces to the advertiser; the user, who is primarily interested in the publishers offering (e.g., the content of a news website) and is sometimes also interested in the ads displayed on the site. Figure 1 outlines the business models of advertisers and publishers; the exchanges that occur among advertisers, publishers and users; and the (often implicit) agreements among them. Figure 1: Interplay among the Essential Actors of the Online Advertising Market Many publishers offer users free access to their contente.g., newsin exchange for the ability to collect data from these users, as well as to provide other actors, such as advertisers, with opportunities to contact the users. Thus, even when users ostensibly receive content without paying for it, they are still payingnot with money but with their data and willingness to view ads. Advertisers pay publishers for the opportunity to contact users and, to a lesser extent, pay for data about those users. Advertisers then proceed to display ads to users and, in cases in which relevant data are available, they may target certain users and even personalize ads to their preferences. Users, in turn, are expected to see those ads and, at least in some cases, to purchase the advertisers offeringswhere a purchase is broadly defined as a desired action that benefits the advertiser (including, for example, buying products, subscribing to an online newsletter, signing up for a test drive of a car, downloading a document, or donating). At the heart of this interplay between the various actors is the tracking of users, which provides advertisers with two key capabilities. The first is the capacity to process data about users for profiling, which enables advertisers to better target ads to appropriate users, and thus to avoid wastage of ads. For example, an advertiser likely prefers to avoid sending a male user an ad for female hygiene products (and the other way around). The second is the capacity to recognize, at least to some extent, whether the ads are successfulwhich, in turn, enables the advertiser to determine whether it is worthwhile to continue spending money on a given publisher (and, ultimately, on the publishers users). For example, if an ad served on a particular publisher does not receive any user reaction (as measured, e.g., by clicks on the ad), the advertiser might then conclude that, for the specific advertisement, the publisher does not attract the right audience, i.e., the right type of user. Alongside these benefits, however, user tracking raises privacy concerns, as elaborated in subsequent sections. 2.2 Scope and Types of Online Advertising The online advertising industry is large and represents an essential part of the economy. Internet advertising revenues have grown consistently over recent years; in 2020, for example, the growth rate in the US was an impressive 12.2%, with revenues reaching $139.8b (IAB 2021). Advertisers spent 70% of all online advertising funds on advertising on mobile devices (including smartphones and tablets) and 30% on desktop platforms. Regarding ad format, the largest share of funds (42.2%, see Figure 2) is spent on search engine ads, i.e., ads delivered via search engines, notably Google. Display advertising (i.e., banner advertising) represents the second-largest share (31.5%), and video advertising, e.g., on YouTube, the third-largest share (18.7%). Other forms of online advertising (e.g., classified advertising, audio formats, lead generation ads) play a minor role. The ad-selling market is highly concentrated; indeed, in 2020, the top 10 publishers realized 78.1% of all advertising revenues (IAB 2021). Google and Facebook are by far the two largest publishers in the Western world. The ad-buying marketing is far less concentrated, i.e., there are no advertisers that dominate the demand side in a manner comparable to Google and Facebook on the supply side. Figure 2: Size and Share of Figure 2: Different Formats of Online Advertising in the US (IAB 2021) Figure 3 outlines the digital advertising spend per capita for selected European countries (IAB 2020). Advertising expenditures per internet user are, by far, highest in the UK (324.70), followed by Norway (231.30), Sweden (229.40), Switzerland (212.40) and Denmark (194.80). In Germany, the average amount spent per Internet user is 113.40. Figure 3: Digital Advertising Spend per Capita in 15 countries (IAB 2020) Figure 3: Digital Advertising Spend per Capita in 15 countries (IAB 2020) 2.3 Real-Time Bidding as a Process of Selling Online Advertising In this subsection, we describe a prominent process of selling online advertising, which we refer to as real-time bidding (RTB), and which is also referred to in the industry as programmatic advertising, because advertisers and publishers use algorithms to buy and sell advertising (Kosorin 2016). The 2021 IAB report (IAB 2021) outlines that 88% of ads (excluding search) sell as programmatic advertising. This process constitutes a key source of concern for regulators and privacy advocates. For clarity of presentation, in what follows, our discussion focuses primarily on online display advertising (also referred to as banner advertising) but selling digital video ads shares many characteristics. Online display advertising is well known to most users and raises many privacy concerns because it often involves exchanging data between firms. It uses an auction-based system to sell ads, as search ads also do. Other forms of advertising, including traditional offline advertising such as TV and outdoor, gradually implement comparable systems. Real-time bidding is a collective term for the technological infrastructure used to sell opportunities to display an ad in real-time and in a fully automated manner (Yuan, Wang, and Zhao 2013, Wang, Zhang, and Yuan 2017). In many cases, selling occurs via real-time auctions that run for less than 100 milliseconds (for reference, a blink of an eye takes 200-400 milliseconds). Ad exchanges (e.g., Xandr), marketplaces that connect advertisers and publishers, frequently serve as platforms for such real-time auctions (Cristal 2014, Kosorin 2016, Lee, Jalali, and Dasdan 2013, Information Commissioners Office 2019; Ada, Abou Nabout, and McDonnell Feit 2022). Figure 4 illustrates the automated auction process under real-time bidding. For convenience, we refer to a scenario in which an ad slot is being sold on a website, but the general process we describe is applicable to other online media that belong to a publisher and contain ad slots, such as apps. As shown in the figure, whenever a user visits a publishers website with ad slots (1), the publisher sends an ad call to an ad exchange (2). This ad call is a request to run a real-time auction on the ad exchange and contains information about, for example, the properties of the ad slot (e.g., ad size) and a user ID, which we explain in more detail in Section 3.1. The ad exchange then sends a bid request to all advertisers on the ad exchange (3). Each interested advertiser submits a bid for displaying its ad to the user; the bid also includes the ad servers address with the ad (4). The ad exchange determines the price and the winner of the auction and forwards this information to the publisher (5). The publisher then asks the users browser to load the ad from the ad server (6), and the ad is subsequently displayed to the user on the publishers website (7). Figure 4: Illustration of the Auction Process in Real-Time Bidding (RTB) This description of the real-time auction process is a simplification, because it only captures essential steps (for more details, see Cristal 2014, Kosorin 2016, Trusov, Ma, and Jamal 2016 or Wang, Zhang, and Yuan 2017). It does not consider, for example, the specific requirements imposed by privacy laws such as the GDPR (which we will outline later in Section 6 when discussing the Transparency and Consent Framework (TCF)). In addition, it is important to acknowledge that there are many other actors that support the activities of advertisers and publishers (Luma Partners 2021). We describe these other actors in the following subsection. 2.4 Description of Other Actors Figure 5 classifies the numerous actors in the online advertising industry into several main groups that we will not all cover here. Figure 5: Overview of Actors in the Online Advertising Industry (DisplayLUMAscape) Note that Luma Partners (2021) refer in this figure to an advertiser as a marketer and to users as people. An ad exchange, as noted above, is a marketplace where the demand side, i.e., advertisers, and the supply side, i.e., publishers, meet to fill ad slots (offered by publishers) with ads (provided by advertisers). A demand-side platform (DSP) is a technology provider that supports the advertiser buying ad slots. A supply-side platform (SSP) provides technology to support the publisher selling its ad slots. An advertising agency helps the advertiser with the creation of the ad. An ad server is a web server (i.e., a computer) that stores advertising content (e.g., banner ads). It delivers that content to the publishers ad slot and, thus, the user (in our setting, the users browser). Many additional actors exist that support the process of selling ad slots and delivering ads to those ad slots. Among them are data management platforms (DMPs), which provide data about the user (e.g., demographics or user interests), or verification providers that verify that an ad appears on the correct publisher. The advertiser and the publisher have to finance all actors. As a result, the price that the advertiser pays for an ad is often much higher than the amount that the publisher receives. Google, for example, outlines that its publishers received over 69% of the money that the advertiser paid (Hsiao 2020). The share of the money that the publisher receives goes further down if the seller and buying of ads involve more actors. For example, the Guardian reports that this share can drop to 30% (Pidgeon 2016). Figure 6 provides a schematic illustration of how the various actors operate together to produce what the user ultimately views (in terms of both content and ads). In effect, when the user visits a publishers website (e.g., a news website), two processes are initiated. The first process (marked in orange) delivers the websites primary content (in our example, news content). This content is available on the publishers content server. The second process (marked in blue) is the process through which ads slots are sold and ads are delivered to the user. Our discussion focuses on the latter process; accordingly, in Figure 6, the process marked in orange is simplified and does not include other actors that may be involved in content delivery, such as measurement and analytics providers that track, for example, how often a user saw certain content and that help the publisher optimize its content. Figure 6: Delivery of Content and Ads from the Users Perspective when Visiting a Website The process of selling ad slots and delivering ads involves the following steps. The publishers ad server recognizes an available ad slot (usually even multiple ad slots) that the publisher would like to fill with an ad. The ad server approaches the supply-side platform (SSP) with a request to sell the ad slot on the ad exchange. The SSP sets up the auction on the ad exchange, and the ad exchange approaches the advertisers, usually via several demand-side platforms (DSPs), with a request for a quote for the ad slot, i.e., offering the opportunity to buy the opportunity to display an ad to the specific user. It is essential to understand that any data that the publisher reveals can spread to many other actors. That is a concern that Ryan (2018) raises. He outlines that it is technically feasible to share a wide range of information along the chain outlined in Figure 6. Such sharing raises privacy concerns. It is, however, less clear whether and how intensively sharing of personal data occurs. 2.5 Main Takeaways The main takeaways from Section 2 are: The three main actors in the online advertising industry are advertisers, publishers, and users. Between each pair of actors, a transaction takes placewhether implicitly or explicitly agreed upon. 70% of online advertising occurs on mobile devices (including smartphones and tablets). The main advertising formats are search engine advertising, online display advertising and video advertising. Real-time bidding is the primary process through which the selling of display advertising occurs. Data sharing in real-time bidding is a source of privacy concerns. Many publishers rely on advertising to finance their content. They often do not charge users, but users then pay by providing publishers and advertisers (often implicitly) with data, as well as willingness to view ads. Selling and displaying online (display) advertising involves many different actors and requires sophisticated technologies. Indeed, the online advertising industry is effectively a high-tech industry. "],["user-tracking-profiling-and-targeting-in-online-advertising.html", "Section 3 User Tracking, Profiling, and Targeting in Online Advertising 3.1 Description of User Tracking Technologies 3.2 Importance of Tracking, Profiling, and Targeting for the Online Advertising Industry 3.3 Implications for Users 3.4 Main Takeaways", " Section 3 User Tracking, Profiling, and Targeting in Online Advertising 3.1 Description of User Tracking Technologies In simple terms, user tracking describes the practice of collecting data about users over time (Kraft, Miller, and Skiera 2021). User tracking gathers data that reveal insights into various characteristics of the user, such as the users demographics (e.g., female), interests (e.g., high interest in fashion), brand preferences (e.g., Adidas), or purchase intentions (e.g., being in the market for sports shoes). Publishers and advertisers can use such tracking of a user over time to generate a profile for the user to target him or her with unique advertising or content. Numerous technologies exist for user tracking; in what follows, we discuss some of the most important ones. For clarity of presentation, in our discussion, we classify the various technologies along two main dimensions: The number of devices on which the user is tracked: just one device (i.e., single-device tracking) versus multiple devices (i.e., cross-device tracking); The number of websites on which the user is tracked: a single publishers website (i.e., first-party website) versus multiple websites (i.e., third-party websites). Figure 7 presents this classification. Figure 7: Categorization of User Tracking Technologies 3.1.1 Single-Device User Tracking Single-device user tracking technologies track a user only on one specific device (e.g., on a desktop computer, mobile phone, or tablet). Moreover, in most cases, single-device user tracking technologies only track a user within one browser (e.g., Google Chrome) on that device. The most popular single-device tracking technologies are first- and third-party cookies. Additional technologies include digital fingerprinting, advertising identifiers, local storage, and tracking pixels. 3.1.1.1 Cookies A cookie (also referred to as an HTTP cookie, Internet cookie, or browser cookie) is, in simplified terms, a small piece of data sent from a publishers or advertisers server (i.e., a website) to a users browser and stored on the users device (Cristal 2014). A cookie usually contains a unique number called a Cookie-ID that identifies the user, e.g., 177239342526456932. Each cookie also has an expiration date, which is the date on which the browser will automatically delete the cookie. Every time a user accesses the website (or one of the websites) to which the cookie belongs (see below for further details on how different types of cookies track users across one or multiple websites), the website reads the cookie and stores its Cookie-ID, alongside information about the users behavior during the visit. In most cases, this information is stored on the server of the firm (i.e., the computer of the publisher or advertiser) that created the cookie. The cookies unique identifier enables the firm to link several visits of the user together. Cookies are stored in the users browser storage (meaning that a particular cookie can typically only link a users visits on a single browser). All major browsers enable users to prevent cookies or to delete cookies. If the user deletes a cookie and, thus, the associated Cookie-ID, the firm can no longer re-identify the user on the next visit to the website. Instead, the firm will consider the user to be a new user and create a new cookie. There is no connection between the new and the old Cookie-ID and the stored data associated with the two Cookie-IDs. There are three types of cookies, respectively data: first-party cookies, second-party cookies and third-party cookies. First-party cookies are installed by the website that the user is visiting, e.g., a publisher such as the New York Times. So, all data collected by New York Times on its website is first-party data. A simple test of whether a cookie is a first-party cookie is whether the cookie comes from the domain whose name appears in the users browser window. A user can easily look up the installed cookies in their browser. For example, in Google Chrome a user could type in the browser space chrome://settings/siteData instead of typing the websites URL they want to visit to see her cookies. A second-party cookie is a cookie set by another website that belongs to the same owner. So, a publishers second-party data refers to data received from the property (e.g., a website or an app) of a publisher that belongs to the same owner. For example, Metas Social Networks second-party data is the data that the social network, Facebook, receives from other properties of the Meta conglomerate, such as Instagram, Oculus, or WhatsApp (Kraft, Miller, and Skiera 2021). A third-party cookie, in turn, is installed by a website that does not belong to the publisher that the user is visiting, e.g., a third-party ad server that is, for example, owned by a large advertising agency such as Havas. Third-party cookies can track a user across multiple websites. Third-party cookies can be placed in a users cookie storage within the users browser via an ad that an advertiser displays on a publishers website. Specifically, because the users browser loads the ads content from the advertisers server, the advertisers server can store a third-party cookie on the users device. So, a publishers third-party data refers to data received from the property of another publisher that does not belong to the same owner and, thus, is a third party. For example, Metas Social Networks third-party data is data that Facebook receives from third-party websites via the Facebook Share Button (among others). Our distinction into first-party and second-party cookies, respectively data, is hardly made. Instead, both types are treated as first-party cookies, respectively data. This treatment is unfortunate because it hides an advantage that conglomerates such as Google or Facebook have. They can obtain consent only once and then bundle the information collected on all of their properties. This ability is in contrast to a situation in which each property belonged to a different owner. For example, Meta combines data from Facebook, Instagram, WhatsApp and Oculus because they all belong to Facebook, despite these firms being all separate legal entities. Ryan (2020) refers to this opportunity as internal data free-for-all. Other forms of cookies exist. Some of these cookies are designed with the aim of better identifying users or making the deletion of cookies more difficult. A supercookie (also called evercookie or zombie cookie), for example, is a cookie that is stored in multiple storages on a users device. The basic idea of a supercookie is that the user does not know where all cookie instances are stored. Consequently, if the user deletes the cookie in several but not all places, then the cookie instances in the remaining places can simply re-create the cookie in the places from which it was deleted. As a result, a supercookie is difficult to delete, enhancing the firms ability to track the user. The online advertising industry has a strong interest in knowing which cookies belong to the same user. However, the fact that different (first- or third-party) cookies use different identifiers makes it very difficult for different websites to identify a single user. For example, the Cookie-ID A-001 on website A and the Cookie-ID B-007 on website B might belong to the same user, but an advertiser bidding to display ads on the two websites has no straightforward way of knowing this. To help alleviate this problem, technologies such as cookie syncing facilitate the exchange of Cookie-IDs that belong to cookies of different websites. Cookie syncing allows an advertiser to link the users third-party Cookie-ID (e.g., Cookie-ID A-001 to the Cookie-IDs of (first- or third-party) cookies sent by other publishers or advertisers (e.g., Cookie-ID B-007). This process enables the advertiser to incorporate the user data associated with the various Cookie-IDs beyond her own Cookie-ID. The process of cookie syncing is usually a part of data-buying and -sharing agreements between different actors in the online advertising industry such as publishers and advertisers, but also ad networks, demand-side platforms (DSPs), data management platforms, ad exchanges, supply-side platforms (SSPs), and various other data providers. Cookie syncing benefits advertisers and publishers by increasing the amount of data available regarding each user, across different platforms, thereby improving the capacity to target users with online advertisements. 3.1.1.2 Digital Fingerprinting Digital fingerprinting involves gathering information about a users device, and exploiting this information to identify the user. Fingerprinting can be either passive or active. Passive fingerprinting involves gathering information about the configuration of a users device. Such a configuration has many attributese.g., CPU type, computer clock skew, display settings, scripts that are used, browser and operating system information, IP address, or language settingsand a passive fingerprint is essentially a string that contains all of this information. For example, the string intel:00:00:01:chrome:windows would be a passive fingerprint that includes CPU type, computer clock skew, browser, and operating system. Because there are so many different ways to configure a device, the specific combination that a particular user has is likely to be unique, thereby providing a means of identifying the user. Still, there is no guarantee that there are no other devices with the same combination of these attributes. Active fingerprints, in turn, are digital fingerprints that include information that is guaranteed to be unique to the users device (e.g., the media access control (MAC) address provided by the chipmaker). To get an active and thus unique fingerprint, the publisher or the advertiser interested in tracking the user installs executable code on the users device and reads its MAC (or another unique serial number). A publisher can use active or passive fingerprinting to track a user on its first-party website. Advertisers can use active or passive fingerprinting to follow a user on third-party websites. Advertisers can obtain the information required to generate a fingerprint by displaying an ad on the publishers website. When the user accesses the publishers website, the users browser loads the websites content from the publishers server, and it loads the content of the ad from the advertisers server (see Figure 6). When the users browser accesses the advertisers server to display the ad, the advertisers server can generate the digital fingerprint. In addition to tracking a user on a third-party website, advertisers (such as Adidas) can also track a user on their own (first-party) websites (e.g., Adidas.com) using active or passive fingerprinting. Behavioral biometric features, namely dynamics that occur when typing, moving, and clicking the mouse, or touching a touch screen, can provide further information to improve active digital fingerprinting and, hence, user identification. 3.1.1.3 Advertising Identifiers Another single-device user tracking technology used on mobile devices (so-called mobile apps) relies on advertising identifiers, called mobile ad IDs (MAIDs). An advertising identifier is a string of hexadecimal digits assigned to a given device by the devices operating system, e.g., Apples iOS or Googles Android. Apples MAID is called Identifier for Advertisers (IDFA), and Googles MAID is called Google Advertising Identifier (GAID). The identifiers are device-specific. Thus, all ad networks in all apps running on the same device will get the same ID. In mobile browsers, the advertising IDs are not usable. Advertising identifiers are nowadays also used for other connected devices such as for example voice assistants, connected television (CTV), or over-the-top (OTT) devices. 3.1.1.4 Local Storage Local storagebased tracking relies on the possibility to store data in the so-called local storage of the users browser. Publishers and advertisers can use the local storage to save text-based information such as a unique user ID and other information to track a users online behavior. The browsers local storage is a place to store items that are usually not passed back and forth constantly to publishers or advertisers servers. Also, first- and third-party websites can access and use local storage to identify a user. The local storage is usually part of the users browser and allows publishers and advertisers to save data with up to 5 MB in the users browser. There is no expiration date for the data stored. Thus, data items within the local storage are available until the website or the user deletes them. One downside of local storage is that it is not very secure. Therefore, unencrypted private or personal information should not be stored in the local storage. 3.1.1.5 Tracking Pixel A tracking pixel (also called a pixel tag, web beacon, action tag, or clear GIF) is a piece of code that creates a 1×1 pixel; this code is embedded either in the HTML code of a publishers websitethereby allowing the publisher to track users on its websiteor in the HTML code of an ad displayed on the publishers websitethereby enabling the advertiser to track the user on the website. Beyond HTML, tracking pixels can also be integrated in JavaScript or an iFrame. When a user visits a website containing a tracking pixel, the browser loads the pixel from the server of the firm (publisher or advertiser) that created the pixel. This loading enables the firm to access the users browser. A tracking pixel allows a firm to track a user because the pixel is loaded from an external URL so that this external URL, respectively the firm behind this URS, can track the user. Tracking pixels are invisible to the user and do not store on a users computing device. Accordingly, without inspecting a websites underlying HTML code, users cannot know whether they are being tracked by a pixel. Tracking pixels can also document how far a user scrolls down a page. 3.1.2 Cross-Device User Tracking Cross-device user tracking technologies enable a users online behavior to be tracked across multiple devices. One means by which firms accomplish cross-device user tracking is by asking a user to log in to a personal account from any device connected to the internet. For example, if a user uses multiple devicese.g., her mobile phone, her laptop, and her desktop computerto access a particular website (e.g., her favorite news website, e-mail service, or social networking site), the website can easily and accurately track her activities across all those devices (and across multiple browsers within those devices) on the basis of her login. As will be elaborated in what follows, a login can facilitate cross-device tracking not only on first-party websites but also on third-party websites. 3.1.2.1 Cross-Device User Tracking on a First-Party Website Technically, a user login on a first-party website is accomplished using a single-device user tracking technology such as a cookie. Suppose a user accesses a website through a web browser on her device. In that case, the website can implement the user login by placing a cookie on the device to remember the user in the future. In this case, the cookie enables a so-called automatic login so that the user does not have to reenter her password every time she visits the website. Such a login identifies a user across multiple visits to the same website. However, firms also use a cookie to keep a user logged in while the user browses multiple webpages during a single visit to a website. Other devices may allow similar tracking tools to enable the website to recognize the device in the future, such as a device-specific advertising identifier on smartphones. The users data is then typically stored on the server of the website that provides the login to the user. 3.1.2.2 Cross-Device User Tracking on a Third-Party Website Another form of user login that tracks the user across multiple third-party websites is the single sign-on (SSO). Here the user login is forwarded by the provider of the user login to other websites. From the users perspective, only one login exists. With this user login, the user can quickly log in to all websites that support the SSO. Examples of SSO providers are Facebook, Google, and the German provider netID. NetID was established in March 2018 as a foundation to offer an independent alternative to the SSO offerings of Google and Facebook (see also Section 9.2). 3.1.3 Comparison of User Tracking Technologies Table 1 presents a comparison of the user tracking technologies discussed in the previous subsections. We compare the various technologies by the following six criteria: User Identification:Describes whether a user tracking technology identifies a user on a first-party website (e.g., the publishers website) or third-party website (e.g., other publishers websites), and whether a user tracking technology identifies a user on a single device (e.g., only on a desktop computer) or on multiple devices (e.g., on a desktop computer and a mobile phone). Storage of User Identifier:Describes whether a user tracking technology stores a users identifier (e.g., a cookie) on the users side (i.e., the users client, for example, a users browser) or on the firms side (i.e., the firms server). Storage of Information on User: Describes whether a user tracking trechnology stores a users information on the users side (i.e., the users client, for example, a users browser) or on the firms side (i.e., the firms server). Expiration of User Identifier: Describes whether a user identifier (e.g., a cookie) expires after some pre-defined date (e.g., after one year of setting the user identifier). Deletability of User Identifier and Information on User: Describes whether the user can delete the users identifier (e.g., a cookie) or the information about the user (e.g., by deleting the users browser cache). Alteration of User Identifier: Describes whether a user can alter the user identifier, for example, by changing the users browser configuration (e.g., choosing a different browser font or language) or by changing the users login information (e.g., the users email address). Table 1 illustrates that the most favorable user tracking technology from a firms perspective is the SSO. An SSO allows a firm to track a user on its own (first-party) website and on other (third-party) websites, as well as across multiple devices (e.g., on the users desktop and mobile device). Because the users identifier and information are stored on the firms side (i.e., the firms server), a firm has more control over the identifier and the data collected on a specific user in the past. In addition, the SSO does not expire (unlike cookies, for example). However, the user can delete or alter the SSO, preventing a firm from connecting existing data to new data from the same user. Despite their advantages, SSOs are difficult for a firm to obtain, as not all firms provide users with sufficient value to justify their signing up for an SSO. In such a case, firms have to rely on other tracking technologies such as cookies, which may also explain cookies enduring popularity as a user tracking technology despite their disadvantages. Table 1: Comparison of Most Important User Tracking Technologies 3.2 Importance of Tracking, Profiling, and Targeting for the Online Advertising Industry In this subsection, we discuss the practical applications of the technologies discussed above, from advertisers and publishers perspectives. Following Kraft, Miller, and Skiera (2021), we distinguish between tracking, profiling, and targeting (Figure 8). Loosely speaking, as noted above, tracking refers to collecting data about users over time (which might include personal data). Profiling involves identifying the data that are valuable for the firm, and using these data to create information about individual users (e.g., characterizing users according to demographic information such as age and gender). This step can enable a firm to distinguish between users that it views as more valuable versus less valuable. Finally, targeting refers to using these profiles to treat some users differently from others. For advertisers, targeting involves selecting profiles of users who are likely to be suitable audiences for a specific ad (e.g., women with kids), or conversely, selecting ads that are likely to be suitable for a specific user. For a publisher, targeting generally involves presenting users with content (e.g., news content for a news publisher) that suits their interests. Figure 8: Relationship between Tracking, Profiling and Targeting for Online Advertising We note that herein, we focus on targeting users on the basis of data that have been collected about them through tracking technologies; this form of targeting is referred to as behavioral targeting in Figure 9. It contains retargeting, also referred to as remarketing or behavioral retargeting (Lambrecht and Tucker 2013; Bleier and Eisenbeiss 2015; Sahni, Narayanan, and Kalyanam 2019). A typical setting for retargeting is an online shop where a user puts a product into a shopping basket but does not purchase it. The online shop can now inform a retargeting provider such as Criteo about this behavior. The retargeting provider then puts up ads of the online shop and the abandoned product on many other websites. So, the user suddenly observes an ad about the specific product on another website (e.g., an online newspaper) even if this website is unrelated to the online shop (Miller and Skiera 2022). Figure 9 outlines that contextual targeting is the other major form of targeting in online advertising. It uses the context in which the user appears (e.g., viewing a news forum on investment advice) to draw conclusions about the users interests and the ads that are likely to be relevant for her. For example, a user reading an article about investment advice might be interested in financial products. Figure 9: Forms of Targeting in Online Advertising 3.2.1 Importance for Advertisers The capacity to accurately target users benefits advertisers in enabling them to avoid wastage, i.e., displaying ads to irrelevant users (users who are unlikely to wish to purchase the advertised products). For example, all else being equal, if an advertiser decreases wastage from 90% to 50%, then for any 10 users viewing the ad, the number of relevant users viewing the ad is expected to increase from 1 to 5. Advertisers are willing to pay for such a decrease in wastage: In our example, since the advertiser becomes five times more likely to reach a relevant user, she might be willing to pay five times more for the ad. A common prerequisite for being willing to pay more for an ad is the ability to measure the success of an ad, and thereby to confirm that the ad is indeed reaching a relevant audience (in our example, this would mean confirming that the number of relevant users has increased from 1 to 5). Many success measures exist, with the most common being the following: users probability of clicking on the ad, referred to as the click-through rate (i.e., the number of clicks divided by the number of impressions of the ad); users probability of converting, referred to as the conversion rate (i.e., the number of conversions divided by the number of clicks on the ad); in many cases, a conversion is defined as a purchase, but the term can also refer to a wide range of other actions that benefit the advertiser, such as subscribing to an online newsletter or signing up for a product demo; the product of the click-through rate and the conversion rate. Advertisers use of the success metrics above is not contingent on user tracking and profiling. That is, advertisers can use these metrics to compare the success rates of different ads, or of the same ad across different contextseven without possessing knowledge of the specific behavior of individual users. Consider, for example, an advertiser who displays two ads for the same product, ad X and ad Y. If the advertiser observes that 50% of users who viewed ad X clicked on it, whereas 0% of users who viewed ad Y clicked on it, then she can determine that ad X was more successful than ad Y, even without knowing which specific users clicked on each ad. Yet, information about individual behaviorobtained through the tracking technologies discussed aboveenables the advertiser to analyze ad success on a more granular level. Going back to our example, let us assume that the advertiser can observe that ad X was viewed by user Aa maleand by user Ba female, and that user A clicked on the ad, whereas user B did not. In turn, ad Y was viewed by users C and Dboth femaleneither of whom clicked on the ad. This information might suggest to the advertiser that females are a less relevant audience for the advertised product, and that ad X was only more successful than ad Y because it was also shown to males. The more detailed the information at the advertisers disposal, the greater the capacity of the advertiser to link users characteristicse.g., demographics and interests such as being female and interested in running shoes to their reactions towards the ad (e.g., their likelihood of clicking the ad). After establishing these links, the advertiser can derive the characteristics of users who are most likely to click, and subsequently target those users, i.e., ensure that ads are displayed only to them. For example, on the basis of user responses, an advertiser selling a protein shake may determine that its target audience is male users between the ages of 30 and 40 who are interested in sports. The advertiser can then ensure that she displays her ad only to users whose profiles match those characteristics. However, it is important to note that though user profiles may contain an enormous amount of information, this information is not always accurate or consistent (Neumann, Tucker, and Whitfield 2019; Kraft, Miller, and Skiera 2021). Erroneous profiles decrease advertisers success with targeted ads and, thus, their willingness to pay for ads. In addition to facilitating user targeting, tracking can enable advertisers to ensure that the same user is not exposed to the same ad too many times. Limitation of exposure can be achieved either through frequency capping, i.e., limiting the number of times a user sees a particular ad, or through recency capping, i.e., making sure that a minimum amount of time has elapsed since the user last saw the ad. Such capping could save the advertiser money and might also avoid annoying the user too much with the ad. Finally, tracking enables the advertiser to conduct attribution modeling. It determines how much value each of several actions (also referred to as events or touchpoints) contributes to the desired outcome. Suppose, for example, that the user clicked on two ads and then purchased a product. The question is then whether both ads contributed equally to that purchase (so an attribution of 50% each) or not. 3.2.2 Importance for Publishers Publishers also have an interest in tracking, profiling, and targeting. First, a publisher may offer a wide range of content, with different levels of appeal for each user. In these cases, the publisher may want to present each user with the content that is most suited to the users interests. For example, a news website could prioritize displaying news about the users favorite sports team or show the weather forecast for the particular area where the user lives. Profiling users can enable publishers to personalize their content in this manner. Second, a publisher can track users to observe what they are doing on the website, and then use this knowledge for various purposessuch as improving the website. For example, user behavior might lead a publisher to make changes to the user interface (e.g., the publisher observes that users often leave the website on a particular page and then realizes that links were missing from the page), to the content of the website (e.g., by recognizing that certain topics of news articles are more attractive than others) or the presentation of the content (e.g., more pictures versus more text and vice versa). The improved website could then attract more users. Third, user tracking enables publishers to document their websites reach. While it is possible to measure a websites overall number of page impressions without tracking individual users, tracking is necessary in order to measure the number of unique (or different) users who visit a websitefor the simple reason that such measurement requires observing whether a given user has visited the website before. Advertisers often prefer publishers with an extensive reach. Accordingly, publishers are interested in reporting a high reach, and advertisers fear that publishers might over-report their reach. To avoid a lack of trust, publishers often ask a (trusted) third party to conduct the measurement, such as AGOF in Germany, which relies on information provided by INFOnline. AGOF also provides examples of their reports on their website (e.g., at www.agof.de/studien/daily-digital-facts/monatsberichte/, however, only in German). The fourth benefit of tracking relates to the fact that the price that a publisher realizes from an ad impression is a function of the advertisers willingness to pay (WTP) to display an ad to a particular user on the publishers website. As discussed above, advertisers value the capacity to target specific users; thus, information that the publisher obtains about the user from tracking can, in theory, increase or decrease ad prices (e.g., Board 2009, Chen and Stallaert 2014, Levin and Milgrom 2010). The following example illustrates how information gathered about a user can influence the ad prices that a publisher commands. Suppose there are two advertisers: Advertiser A, a producer of sports cars, and advertiser B, a producer of SUVs. Both advertisers prefer to target male users over female users. The advertisers are informed that an ad impression is available on a car review website. If the advertisers are informed that the user who will view the ad impression is maleas opposed to being provided with no information about the users gendertheir WTP may increase, leading to higher bids in the auction. As a result, the final price that the publisher receives for this impression can increase. Yet, the influence of individual information on ad prices is not always straightforward. Suppose that, in addition, to determining that the user is male, the publisher has also determined that the user is interested in sports cars. This information might increase the WTP of advertiser A even morebut the WTP of advertiser B could decrease. In this case, the auction could lead to a lower price than in the situation where both advertisers only had information about the users gender. Thus, theoretically, information about a user can increase or decrease ad prices. Empirical evidence suggests, however, that, on average, more information leads to higher ad prices (Johnson, Shriver, and Du 2020; Laub, Miller, Skiera 2021). 3.3 Implications for Users 3.3.1 Personalization of Content Personalization of content on publishers websitessuch as news feeds on social networks or product recommendations on online shopping or streaming platformscan increase users utility by providing them with experiences more directly related to their interests (Celis et al. 2019). It is important to acknowledge, however, that in providing personalized content, a publisher may seek to enhance not only the users utility but also its own profit. Though these two perspectives may be alignedbecause it is hard to make a profit by exposing a user to products or content that she is not interested inthey can still differ. For example, if product A provides slightly more utility to a user than product B, but the firm makes much more profit on product B, the firm is tempted to recommend product B. Content personalization may also have certain disadvantages from the users perspective. because an algorithmic recommendation can result in a filter bubble, also referred to as an echo chamber. In a filter bubble, a user is exposed only to content that is aligned with the users own cultural background or ideologya situation that is, at least in the long-run, in the interest of neither the user nor society. Furthermore, personalized content also discloses the preferences of the user, which the user might not appreciate. 3.3.2 Personalization of Ads In addition to seeking to persuade users, advertising serves an informative functionfor example, making users aware of products they may wish to purchase. Consequently, personalized (targeted) advertising may benefit users in providing them with information that is relevant to them, thereby helping them make better purchase decisions (for additional information on how users benefit from personalized ads, see a review by Boerman, Kruikemeier, and Borgesius 2017). Personalized advertising can also benefit users in more indirect ways. The most obvious is that better targeting of ads enables the publisher to command higher prices for adsand this revenue may enable the publisher to provide more content for free, i.e., without charging a fee to users. Notably, as discussed in Section 2.1, such content is not actually free, as users pay for it with their data and with the attention they devote to ads. Still, some users (e.g., those with little income) may prefer this mode of payment instead of paying with actual money. 3.3.3 Privacy From the users perspective, the major drawback of tracking is a violation of privacy. In general, surveys consistently suggest that users are uncomfortable with the idea of firms tracking their behavior over time and building up profiles. For example, a survey in 2019 showed that 79% of users worldwide are concerned about how firms use their data (Pew Research Center 2019). In another survey, 40% of users indicated feeling they have no control over their data (Presthus and Sørum 2018), partly due to an inability to oversee which data firms collect. These reports notwithstanding, it is complex to evaluate users actual preferences with regard to their privacy, because there is a significant disparity between users stated preferences concerning privacy and the actual steps they take to protect it. This disparity is referred to as the privacy paradox (Aguirre et al. 2015, Norberg, Horne, and Horne 2007, Beke, Eggers, and Verhoef 2018). Usually, stated preferences reflect a desire for high privacy levels, whereas revealed preferences reflect an acceptance of substantially lower levels. For example, Gross and Acquisti (2005) scraped users real-world social media privacy settings and found that few (1.2%) had altered permissive default settings. Athey, Catalini, and Tucker (2017) also documented a large gap between stated and revealed preferences for privacy. Regardless of what users actually prefer, and as we will see below, regulators have concluded that a users loss of privacy outweighs the potential benefits that come with better personalization of content and ads. 3.4 Main Takeaways The main takeaways from Section 3 are: Cookies are a popular tracking technology, but they only track a users behavior on one device and in one browser. Furthermore, users can easily delete cookies or prevent that firms set cookies. Single-Sign-On (SSO) is the most favorable user tracking technology from a firms perspective. However, not all firms provide users with sufficient value to justify signing up for an SSO service. This shortcoming of SSOs may explain the enduring popularity of other tracking technologies, such as cookies. Advertisers and publishers benefit from tracking, profiling, and the resulting ability to target users with personalized content or ads. Tracking also enables advertisers to measure the success of advertising. It is challenging to evaluate whether users benefit from tracking, profiling and targeting. It requires trading-off between certain benefitssuch as utility from a more personalized browsing experienceand drawbacks, particularly a loss in privacy. Measuring users preference for privacy is tricky, because most users say that privacy is importantbut their actions reveal a far more lenient stance toward privacy, a phenomenon called the privacy paradox. "],["personal-data-processing-under-the-gdpr.html", "Section 4 Personal Data Processing under the GDPR 4.1 Aim and Scope of the GDPR 4.2 Definition of Personal Data 4.3 User Rights with Regard to Personal Data Processing 4.4 Obligations for Firms that Process Personal Data 4.5 Specific Conditions Regarding Legal Bases for User Tracking Technologies 4.6 Legal Bases for Tracking under other Privacy Laws 4.7 Main Takeaways", " Section 4 Personal Data Processing under the GDPR 4.1 Aim and Scope of the GDPR The General Data Protection Regulation (GDPR) became effective in all member states of the European Union on May 25, 2018. The regulation aims to increase consumer privacy by (i) strengthening consumers control over their personal data (see Section 4.2 for the GDPRs precise definition of personal data); and (ii) harmonizing EU member states existing national privacy laws via one regulation for all EU member states. The GDPR achieves these aims both by defining users rights with regard to their personal data (see Section 4.3) and by imposing obligations on firms that process such data (see Section 4.4). As elaborated in what follows, the GDPR defines the concept of personal data processing rather broadlyencompassing the collection of personal data, as well as the use and ultimate deletion of such data. Unlike previous EU privacy laws, which only affected European firms, the GDPR applies not only to EU firms but also to firms outside the EU that process EU citizens personal data. The only case in which the GDPR treats European firms and non-European firms differently is with regard to the processing of personal data of non-EU citizens; in these cases, the GDPR applies to European firms but not to non-European firms, as outlined in Table 2. Table 2: Applicability of the GDPR for EU and non-EU Firms Processing Personal Data of EU and non-EU Citizens 4.2 Definition of Personal Data The GDPR defines personal data as follows (Article 4): [] any information relating to an identified or identifiable natural person (data subject); an identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person. According to this definition, and in contrast to prior regulations, which only considered information that directly identifies a consumer (e.g., name, address, birth date, or social security number) as personal data, the GDPR considers personal data to include any information that directly or indirectly identifies a user (Bleier, Goldfarb, Tucker 2020). Information that can indirectly identify a user includes online identifiers such as cookies and digital fingerprints. Therefore, firms that adopt such tracking techniques have to comply with the GDPR. The GDPR strictly differentiates between pseudonymous data, to which the GDPR applies, and anonymous data, to which the GDPR does not apply. Personal data are considered pseudonymous if they do not directly identify a user but can be used to identify a user indirectly. For example, a customer number (e.g., 123456789) does not, in itself, directly identify a user. However, when combined with information relating the customer number to an individual user (e.g., 123456789 represents user X), the customer number is considered pseudonymous data. Personal data are only considered anonymized if they do not identify a user at all (e.g., it is unknown which user the customer number 123456789 represents). Thus, firms that collect data from consumers and seek to avoid the GDPR cannot suffice with pseudonymizing user information but rather must anonymize it, which may be impractical and costly. 4.3 User Rights with Regard to Personal Data Processing The GDPR provides users with eight rights related to the processing of their personal data. In what follows, and as summarized in Table 3, we classify these rights into three categories: rights that enable users to understand the processing of their personal data (Section 4.3.1); to change the processing of their personal data processing (Section 4.3.2), and to restrict the processing of their personal data (Section 4.3.3). Table 3: Overview of User Rights and Their Aims under the GDPR 4.3.1 Rights Enabling Users to Understand the Processing of Their Personal Data The Right to Information states that a user has a claim to information about any firm that processes the users personal data and about the firms personal dataprocessing activities. Such information includes the contact details of the firm, which types of personal data the firm processes, and the rationale behind the processing. For example, if a user shops on an online platform, and the platform processes data from the user, then the user has the right to obtain contact details of the online platform. Moreover, the user has the right to know if the firm has collected data about the products the user viewed and is using this information to recommend other products to the user. This information puts the user in the position to contact the firm and enables the user to evaluate whether she agrees to the personal data processing. The Right to Access entitles users to obtain copies of their personal data and further information about the personal data processing. In our example, the user who shops on the online platform can ask for a copy of the personal data that the online platform has stored about her, and for information about all personal data processing activities. Notably, this right forces firms that process users personal data to document all of their processing activities. The Right to Access enables users to gain an in-depth understanding of which personal data the firm processes for what purpose, providing additional information that can assist them in evaluating whether to consent to having their personal data processed. 4.3.2 Rights Enabling Users to Change the Processing of Their Personal Data The Right to Rectification provides a user with the opportunity to modify and correct potentially false or outdated personal data, which may harm the user otherwise. For example, in a situation in which a users financial information was processed for the purpose of determining credit eligibility, it may be that the user was not solvent and, thus, not eligible for credit. However, once the user becomes solvent, the user may rectify the personal data about the insolvency, potentially preventing the information from harming future credit applications. The Right to Erasure enables the user to force the firm that has processed the users personal data to delete data that are not relevant for the purpose of the personal data processing. This right enables the user to negotiate with the firm about the relevance of personal data and puts the firm in the position to justify the personal data storage if the firm does not agree with the erasure. In our example, the user who became solvent may ask the firm to delete the past information about the users insolvency because this personal data may not be relevant to assess the users current solvency. The Right to Data Portability enables the user to ask the firm to provide all personal data of the user to another firm in an accessible and machine-readable format. For example, a user may ask her current bank to transmit all her personal data to a new bank. This right decreases lock-in effects caused by so-called switching costs. Switching costs occur if the user faces costs caused by switching from one firms service to another firm. 4.3.3 Rights Enabling Users to Restrict the Processing of Their Personal Data The Right to Restriction of Processing enables a user to stop the processing of her personal data (temporarily) if the user doubts (i) the necessity to use the personal data to fulfill the purpose of the processing, (ii) the accuracy of (some of) the personal data used to achieve the purpose of the processing, or (iii) the lawfulness of the processing. Therefore, this right enables the user to take actual control of her own personal data and requires the firm to justify (i) the necessity, (ii) the accuracy and (iii) the lawfulness of the personal data processing. For example, suppose a user applies for credit, and an algorithm decides, on the basis of the users personal data, whether the user should receive the credit. If the user determines that the personal data used to make this decision are unnecessary, incorrect, or illegally processed, then the user can demand that the website stops processing the personal data. The Right to Avoid Automated Decision-Making ensures that the user has the right not to be subjected to a decision based solely upon automated processing, including profiling. This right applies primarily to cases in which decisions significantly impact the user, such as the refusal of an online credit application. More specifically, this right enables the user to demand that the data-processing firm assign humans to monitor decision-making processes that are otherwise carried out automatically, as humans may better detect mistakes in such processes. For example, if a users credit application is rejected on the basis of an automated decision, then the user can object to the automated decision-making process and request that the firm (partially) re-evaluate this decision via a human. The Right to Object entitles the user to object to the processing of personal data for marketing purposes, including marketing-related profiling. More specifically, this right enables users to ensure that they do not receive content or ads based on their past browsing behavior, demographics or interests. Therefore, this right enforces the users fundamental right of informational self-determination. Returning to our example, suppose that the user who has applied for credit begins to receive advertisements based on the users solvency rating. In this case, the user can object to this targeting strategy and can demand to see untargeted ads, which do not relate to the users solvency rating. In order to override a users objection to the processing of personal data, a firm must demonstrate compelling legitimate grounds for doing so. 4.4 Obligations for Firms that Process Personal Data 4.4.1 The Role of the Firm: Data Controller or Data Processor According to the GDPR, a firm that handles a users personal data is classified under one of two essential roles: data controller or data processor. Each role entails specific responsibilities and obligations with regard to the processing of personal datawhere a data controller has more obligations than a data processor. It is possible for a firm to be a data controller in some cases and a data processor in others, but never both simultaneously. 4.4.1.1 Definition of Data Controller The GDPR defines in Article 4 point (7) that a firm is a data controller if the firm has the obligation of deciding why and how to process the personal data (the purposes and means of processing). Under the GDPR, the data controller faces several obligations, which we discuss in Section 4.4.2 and Section 4.4.3. 4.4.1.2 Defintion of Data Processor The GDPR outlines in Article 4 point (8) that a firm is a data processor if it processes personal data on behalf of a data controller. Thus, the data processor cannot decide why and how to process the personal data (the purposes and means of processing). We discuss the obligations of the data processor in Section 4.4.2. 4.4.1.3 Relationship Between Data Controller and Data Processor By definition, a firm cannot be both a data controller and a data processor for the same personal data processing activity; it must be one or the other. Yet, a firm might be involved in multiple personal data processing activities (potentially even involving similar data)and serve as a data processor in some activities and as a data controller in others. For example, suppose that a demand-side platform (DSP) D receives a bid request from an ad exchange to bid on behalf of an advertiser A1 for a particular ad slot. That bid request comes with personal data such as the user ID (or cookie ID) for the user who will be exposed to the ad, the publisher P1 to which the ad slot belongs, and the information that the user is likely to be male. Concerning this bidding process, DSP D is a data processor because it processes personal data on behalf of the data controller (i.e., publisher P1, which sells the ad slot). Assume further that DSP D also bids on behalf of another advertiser, advertiser A2, for an ad slot offered by a different publisher, P2. In this bidding process, advertiser A2 also receives personal data. DSP D remains a data processor for this bidding process because it processes personal data only on behalf of the data controller (i.e., publisher P2, which sells this ad slot). However, DSP D turns into a data controller if it combines the personal information received from publishers P1 and P2. For example, DSP D could develop profiles about users that contain information that both publishers provided to sell these profiles to advertisers. The profiles are now the firms own data. Therefore, the firm becomes a data controller. 4.4.2 Shared Obligations for Both the Data Controller and Data Processor The GDPR stipulates several obligations with which both types of actorsthe data controller and the data processormust comply in order to engage in a particular activity involving the processing of personal data. Table 4 outlines the most important ones. Table 4: Overview of Obligations for both Data Controller and Data Processor under the GDPR The first obligationprocessing any personal data based on a legal basisentails justifying the data processing activity by choosing an appropriate legal basis; the GDPR stipulates six arguments that constitute acceptable legal bases for personal data processing. The choice of a particular legal basis may be associated with additional requirements. Section 4.4.4 provides a detailed discussion of the various legal bases and the requirements associated with each one. While the data controller and data processor both need a legal basis, the choice of the legal basis is solely down to the controller. As such, the data processor relies on the legal basis chosen and established by the data controller. The second obligation is for the actor to document all steps taken as part of the personal data processing activity, including the choice of a legal basis and the measures implemented to ensure compliance with all obligations. Third, the actor needs to implement appropriate technical and organizational measures to safeguard privacy by default and design. Finally, in the case of a data breach, the data controller is usually required to notify the personal data breach to the supervisory authority within 72 hours. In contrast, the data processor is required to notify the personal data breach to the data controller immediately. For example, suppose that a firm has a database of customer email addresses (i.e., personal data), and it wants to send a newsletter to its customers to inform them about a sales event. To this end, the firm must process the email addresses, e.g., by gathering relevant email addresses from the database and sending the newsletter to these addresses. According to Table 4, the firm first needs a legal basis for this activity. Suppose that the firm chooses to rely on users explicit consent as its legal basis (see Section 4.4.4.2.2 for a detailed discussion of explicit consent as a legal basis for data processing). In that case, the firm has to collect users explicit consent to have their email addresses used for receiving newsletters. Moreover, once the firm has chosen explicit consent as its legal basis, it needs to fulfill all associated requirements stipulated in the GDPRe.g., informing the user of the purpose of personal data processing prior to requesting consent. Second, the firm needs to document all its activities with regard to the processing of users email addresses. Notably, in line with the users Right to Access (Section 4.3.1), if the user requests this documentation, the firm must provide it. Third, the firm must implement appropriate technical and organizational measures to safeguard personal data. For example, the firm could encrypt the files in the database to protect the email addresses from being stolen, or store more sensitive personal data about the users in a different database with pseudonymized email addresses. Fourth, the firm needs to inform the supervising authority in the case of a data breach. If the firm hires a digital marketing agency to promote its sales event, then the marketing agency acts as a data processor. As such, it relies on the legal basis, i.e., explicit consent, chosen and established by the firm. However, similarly to the firm, the marketing agency needs to document all personal data processing activities, implement appropriate technical and organizational measures to safeguard personal data, and inform the data controller in case of a data breach. 4.4.3 Obligations for Data Controller but not Data Processor The GDPR stipulates several obligations that apply to the data controller but not to the data processor. Table 5 outlines the most important ones. Table 5: Overview of Obligations only for Data Controller and not for Data Processor These additional obligations include a requirement for the data controller to select the purposes of processing personal data before processing the personal data. Continuing our previous example, for the firm processing consumers email addresses, the purpose of data processing might be informing customers about a sales event. An additional obligation that the data controller must fulfill is to justify the relevance of all personal data that the data controller processes. In our example, the firm needs to be able to justify the relevance of processing the email addresses and any other personal data involved in this processing activity, such as names. If the firm is unable to justify the relevance, then the user might rely on the Right to Erasure to have the irrelevant personal data deleted. Regarding the firms purpose to inform customers about a sales event, the firm might justify the processing of email addresses by referring to the requirement that the firm needs the customers email addresses to send them emails about the sales event. A further obligation for the data controller is to ensure the compliance of the data processor with the GDPR. So, if the firm relies on a marketing agency to inform its customers about the sales event, the data controller needs to make sure, that the data processor fulfills all obligations of the GDPR regarding the specific personal data processing activities. 4.4.4 Obligations with Respect to Legal Bases As noted in Section 4.4.2, both the data controller and data processor are required to base the processing of personal data on a legal basis. Article 6 of the GDPR, Lawfulness of processing, defines six possible legal bases for data processing, and a firm must be able to document the presence of one of these legal bases in order to be able to lawfully process personal data for a specific purpose. The applicability of each legal basis varies across industries. In what follows, we elaborate on each legal basis based on the legal definitions made within the GDPR, classifying them according to whether or not they are relevant for the advertising industry. 4.4.4.1 Legal Bases not Relevant for Advertising 4.4.4.1.1 Vital Interest The legal basis of vital interest applies to processing activities that are necessary to protect vital interests of the user or another natural person (Art. 6 point (1d), GDPR). A vital interest exists if personal data processing aids in protecting a persons life (Recital 46, GDPR). In other words, this legal basis applies to processing activities necessary for matters of life and death, such as medical emergencies: If an individual has life-threatening injuries from an accident and medics admit her to a hospital, then the processing of the individuals personal data, e.g., to admit the patient to the hospital, is necessary to protect the individuals life. Due to its nature, the legal basis of vital interest does not apply to firms within the online advertisement industry. Indeed, online banner advertisements cannot convincingly be a matter of life and death. 4.4.4.1.2 Public Interest Public interest serves as a legal basis for processing activities that are necessary to enable tasks that are of public interest or in the exercise of official authority (Art. 6 point (1e), GDPR). For example, a public interest may exist if the firm is a public authority. Another example might be the processing of personal data, e.g., the name and address of an individual, for national elections, as the processing serves the public. Similarly to vital interest, public interest is unlikely to apply as an appropriate legal basis for firms within the online advertising industry. Unless firms are official authorities, online banner advertisements are unlikely to serve a public interest. 4.4.4.1.3 Legal Obligation The legal basis of legal obligation applies if personal data processing is necessary for compliance with a legal obligation that binds a data controller or processor (Art. 6 point (1c), GDPR). An example of a processing activity based on a legal obligation is if a court processes personal data when inviting witnesses. Due to its nature, the legal basis of legal obligation is unlikely to serve as the most appropriate legal basis for personal data processing within the online advertising industry. 4.4.4.1.4 Contract Fulfillment The legal basis of contract fulfillment applies if a data controller or processor has to process personal data in order to enable a user to enter into or complete a contract (Art. 6 point (1b), GDPR). Such a legal basis might be applicable, for example, to a retailer selling clothes online: To complete a transactioni.e., enter into a contract with the retailerthe user needs to provide personal data such as a name, shipping address, and credit card information. Without the processing of such information, the contract between the two parties (provision of clothing in exchange for payment) cannot be fulfilled. Data controllers may claim the legal basis of contract fulfillment when setting so-called strictly necessary cookies on their websites. Strictly necessary cookies, also called technically necessary cookies, are essential for a website to function and for the user to use the websites features. Such cookies include, for example, those that enable websites to process payment information or to save items placed in a shopping cart. Although contract fulfillment can be an applicable legal basis for using (strictly necessary) cookies, it currently does not serve as a legal basis for personal data processing for the purpose of online advertising. More specifically, cookies used for online advertising cannot be categorized as strictly necessary. Thus, contract fulfillment currently cannot serve as a legal basis for firms in the advertising industry. With the rise of the PUR model (see Section 5.2.2.2), however, contract fulfillment might play a more important role. 4.4.4.2 Legal Bases Relevant for Advertising 4.4.4.2.1 Legitimate Interest Firms can apply the legal basis of legitimate interest if the personal data processing is necessary for the legitimate interest pursued by a data controller or a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the [user] (Art. 6 point (1f), GDPR). To be able to claim this legal basis, a data controller must provide documentation on a case-by-case basis showing that its own legitimate interests in processing a users data outweigh the users interests in not having the data processed. If a firm uses the legitimate interest claim as a legal basis for carrying out personal data processing activities, the firm needs to be transparent about the personal data processing activities and further inform the user that and how they can object to these activities (Art. 21, GDPR). Therefore, loosely speaking, legitimate interest represents the opt-out approach of personal data processing: If the user does not opt-out of personal data processing based on legitimate interest, data controllers can process personal data. A firm may make the argument that data processing for marketing activities serves a legitimate interest. For a publisher, for example, collecting and using personal data can enable behaviorally targeted ads to be served to users, thereby generating revenues for the publisher (which, in turn, may offer its content for free to userssuggesting that the users interests are not harmed). At the same time, if a user might not reasonably expect personal data processing, it is harder for a firm to argue that a legitimate interest to process the personal data exists. Thus, legitimate interest may be a legal basis that firms can use to justify the processing of users personal data. However, the Data Protection Authority responsible for a firm has to decide upon its applicability on a case-by-case basis. Yet, the applicability for the legal basis of legitimate interest for tracking activities will likely be limited in certain countries. For example, Germany eliminated the possibility to use legitimate interest for online tracking technologies with the Telecommunications and Telemedia Data Protection Act (TTDSG) that entered into force in December 2021. 4.4.4.2.2 Consent The GDPR regulates the legal basis of consent in Article 6 point (1a) and in Article 7. A user may give consent for one or more specific purposes of personal data processing activities. Valid consent under the GDPR stipulates a privacy-preserving default, the opt-in approach, that we call explicit consent. This opt-in approach stipulates that without action by the user, the user does not give consent. Additionally, consent needs to be: Freely given: The user should not be or feel persuaded to give her consent. The consent must be given voluntarily, i.e., offering a real choice to the user. Above all, access to content or a data controllers offering must not be conditional on consent. Yet, there have been some cases in which DPAs allow the access to content being conditional on consent. Such a case would be the presence of an equivalent paid alternative (as, e.g., the Austrian DPA ruled in 2019, Datenschutzbehörde 2019). Specific: The user has to give consent for specific purposes and third parties. Informed: Before giving consent, a user needs to have access to information about the personal data processing and to be able to understand what the user is consenting to. This information should include the nature of personal data processed, the purposes of the personal data processing, who will have access to the data, and how the data controller safeguards the data. Unambiguous: There must be no doubt whether a user has consented and to what a user has consented. Made with a clear affirmative action: The user has to actively and explicitly give her consent. Without action by a user, the data controller cannot obtain consent. Furthermore, after a user has given consent for a specific personal data processing activity, the user has the right to revoke the consent. It must be as easy for the user to revoke her consent as it is to provide consent. The user must be able to withdraw previously given consent at any point in time. If a firm fulfills all of these requirements, it has obtained the users valid consent. An example of valid consent under the GDPR would be this scenario: A data controller informs the user about the personal data processing, the purposes of that personal data processing, and the third parties that will have access to the data. After viewing this explanation, the user can tick several un-ticked boxes for each purpose of the personal data processing separately. The data controller informs the user that and how she can withdraw consent at any time. A user can access the service even if she denies consent. To summarize, consent is a legal basis that firms within the online advertising industry can use for personal data processing. Under the GDPR, consent is contingent on an opt-in approach. This approach likely makes personal data processing transparent to the user. 4.5 Specific Conditions Regarding Legal Bases for User Tracking Technologies As the GDPR affects all processing activities that enable individuals to be identified, the tracking technologies discussed in previous sectionsincluding login data, digital fingerprinting, and cookiesare all within the scope of the GDPR. As such, these technologies should presumably be subject to the conditions outlined above regarding the applicability of the various legal bases. Yet, recent state court decisions have imposed additional restrictions with regard to the use of tracking technologies in the advertising industry specifically. In particular, the applicability of legitimate interest as a legal basisone of the two legal bases that are relevant for the advertising industry (the other is consent; see Section 4.4.4.2)has been limited with regard to tracking technologies that serve advertising purposes. For example, in May 2020, the German Federal Court of Justice reinforced the Planet49 ruling by the European Court of Justice of October 2019, which effectively limits the use of legitimate interest as a legal basis for tracking technologies, instead requiring that data controllers and processors obtain valid consent (Information Commissioners Office 2019). The EU tried to mitigate uncertainties about the applicability of legal bases and the practical implementation of the GDPRs requirements for the digital world by drafting another regulation, the ePrivacy Regulation, which we discuss in Section 9.3.3. This regulation intends to extend but not replace the GDPRs requirements in online settings. In particular, it should regulate questions and uncertainties regarding online marketing. However, this regulation has no finalized draft as of June 2021. Consequently, it is currently difficult to claim legitimate interest as a legal basis for user tracking in online advertising. This situation might change once the ePrivacy Regulation is finalizedthough this is not very likely. 4.6 Legal Bases for Tracking under other Privacy Laws Though this chapter focuses on the EUs GDPR, it is important to acknowledge the numerous other privacy laws worldwide that handle various aspects of privacyin some cases, similarly to the GDPR, and in others, slightly differently. In Table 6, we compare some of these lawsspecifically, with regard to their handling of legal bases for the processing of personal data in general, and for the use of tracking technologies in the online advertising industry specifically. Table 6 shows that most major privacy laws worldwide require the same legal bases for tracking that the GDPR requires. Some privacy laws even allow for legal bases other than those allowed by the GDPR (Brazils LGPD, Indias PDPB, Chinas PIPL). Moreover, most privacy laws (LGPD, PDPB, PIPL, and Thailands PDPA, in addition to the GDPR) entail similar criteria for valid consentnamely, users must provide consent explicitly (an opt-in approach), in a free, specific, informed, and unambiguous manner (see Section 4.4.4.2.2). Thus, any firm worldwide that caters to users based in the EU, Brazil, India, China, or Thailand must comply with these requirements for consent. Californias Consumer Privacy Act (CCPA) is the only major privacy law that stipulates an opt-out approach to consent, i.e., users consent is assumed unless they actively object to personal data processing activities. The various countries also differ in terms of the penalties they impose for infringement of privacy laws. A firm that infringes on the GDPR can be required to pay a fine of up to 4% of its global annual turnover or 20 million, whichever amount is higher. Under the LGPD, fines can reach up to 2% of a firms global annual turnover. The PDPA and CCPA, in turn, specify flat sums at which firms can be fined: up to 5 million Thai Baht ($150,000) for the PDPA and up to $7,500 for the CCPA. For grave violation against the PIPL, a firm must pay a fine of up to 5% of its annual turnover or 50 million Yuan (around $8 million). Moreover, the directly responsible person in charge can be fined under PIPL between 10 thousand and 1 million Yuan ($1,600 to $160,000). So, Chinas privacy law (PIPL) is roughly as strict as the GDPR in terms of fines, the legal bases and the requirement of consent from the user to use their personal data. Table 6: Comparison of Legal Bases for Tracking in Major Privacy Laws Worldwide 4.7 Main Takeaways The main takeaways from Section 4 are: The GDPR is a privacy law of the European Union applicable to all European firms and all firms processing personal data of European citizens. The GDPR aims to give users more control over their personal data by defining user rights to understand, change, and restrict the personal data processing. The GDPR increases responsibilities for all actors who process personal data. For a given data-processing activity, the GDPR defines an actor as either a data processor or a data controller, where data controllers have more obligations than data processors do. Data controllers are also responsible for the legal compliance of the cooperating data processors. The GDPR stipulates that in order to process personal data, a firm must specify a legal basis for personal data processing. For firms in the advertising industry, the two applicable legal bases are legitimate interest and consent. Loosely speaking, legitimate interest represents the opt-out approach for getting permission for personal data processing, whereas consent represents an opt-in approach. Even though the GDPR identifies both consent and legitimate interest as applicable legal bases for firms in the advertising industry, courts have reduced the applicability of legitimate interest, consequently favoring consent. "],["effects-of-the-requirement-for-a-legal-basis-for-data-processing-on-the-online-advertising-market.html", "Section 5 Effects of the Requirement for a Legal Basis for Data Processing on the Online Advertising Market 5.1 Effects Independent of the Outcome of the Users Decision 5.2 Effects Dependent on the Outome of the Users Decision 5.3 Main Takeaways", " Section 5 Effects of the Requirement for a Legal Basis for Data Processing on the Online Advertising Market Among the numerous changes introduced by the GDPR with regard to the processing of personal dataincluding new rights for users, as well as new obligations for firmsthe most meaningful change for the advertising industry is perhaps the requirement for firms to supply a legal basis for data processing. As discussed above, in the advertising industry, this requirement implies that firms must inform the user about all processing activities, including tracking, and obtain the users permission for these activitieseither explicit, in cases in which consent serves as the legal basis; or implicit, in the form of non-objection to data processing, in cases in which legitimate interest serves as the legal basis. Before the introduction of the GDPR, the default was that actors in the online advertising industry could process the users personal data at willand users who wished to reduce or prevent tracking could only do so by installing anti-tracking software or altering their browsers settings. Accordingly, the requirement to obtain user permission for data processing constitutes a profound change in the operations of the online advertising industry. This section elaborates on how this change affects the various firms operating in the advertising market, the users themselves, and the interplay between them. We distinguish between effects that are independent of the users decision, i.e., granting or denying permission for data processing (Section 5.1), and those dependent on the users decision (Section 5.2). 5.1 Effects Independent of the Outcome of the Users Decision 5.1.1 Effects of Asking for Permission 5.1.1.1 Effects on Firms Operating in the Online Advertising Industry In practice, a common approach by which publishers inform users of data processing activities and obtain their permission for such activities is by implementing cookie banners (named after the predominant tracking technology, see Section 3.1), also referred to as consent banners. A publisher displays a cookie banner to the user when she first visits its website. Figure 10 shows an example of such a cookie banner. Figure 10: Example of a Cookie Banner (here: www.ecodibergamo.it) The crucial challenge for the publisher is to implement a cookie banner that is compliant with the GDPR, i.e., provides comprehensive information, and that is user-friendly, i.e., does not deter the user. Furthermore, this information needs to cover the purposes of personal data processing and identify all firms that get access to the data. Thus, the cookie banner can become tedious to read for the user, which can conflict with the users aim, namely, to consume the websites content instantly. In order to develop and implement a user-friendly and GDPR-compliant cookie banner from scratch, a publisher would need to invest in human resources like lawyers, data privacy experts, user experience designers, and web developers. Yet, a new actor has emerged to assist publishers, particularly smaller ones, in producing such banners in a less costly manner: namely, firms that offer Consent Management Platforms (CMPs). We describe them in more detail in Section 6.1. 5.1.1.2 Effects on the User When a user visits a publishers website for the first time, the users browser has to load the cookie banner and the websites content. Loading a cookie banner takes several seconds (Hils et al. 2020) and increases the time until the user can access the publishers content. Thus, the presence of a cookie banner can impair users online experience, particularly when users do not have a fast Internet connection. Furthermore, the user needs to respond to the cookie banner that requests permission for personal data processing. Since there is no single universal design for cookie banners, the user faces various cookie banners across websites (Degeling et al. 2019). These cookie banners differ in several dimensions, such as the position on the website, the number of layers (nested sites of the banner), and the buttons to select. Given the interest of the online advertising industry in getting permission for all purposes, particularly tracking, profiling and targeting (Section 3.2), the publisher has an incentive to lead the user to an accept all decision. Therefore, cookie banners are often designed so as to make it easy for the user to click an accept all or allow all button, i.e., to grant permission for all specified purposes of the publisher. Such a design might entail, for example, presenting an accept all option on the first layer of the cookie banner, i.e., the part of the cookie banner that the user instantly sees. Compared with granting permission, denying permission for data processing is often less straightforward for the user. For example, many cookie banners do not provide a deny all button (Sanchez-Rola et al. 2019) on the first layer and instead require the user to open a second layer, e.g., by clicking on a settings button (Schmitt 2021). Suppose the user wants to make a more differentiated decision and only wants to give or deny permission for specific purposes, such as the use of personal data for ad performance measurement. In that case, the user also needs to access the second layer and go through all the specified purposes, selecting the ones that are acceptable to her. Thus, the user needs to process more information and click more times than she would have to had she selected the accept all option (or the deny all option, if available). This scenario illustrates that a decision deviating from the accept all option increases the users effort and the amount of time she must wait until she can access the websites contentthereby impairing the users online experience. In Section 8.4, we present an empirical study that provides evidence for the number of decisions a user typically makes when faced with a cookie banner, and the average time spent making each decision. Notably, developers have created various non-commercial tools to streamline the decision-making process, with the aim of preventing cookie banners from impairing the user experience. We discuss these tools in Section 6.2. Summing up, users gain benefits from the requirement for publishers to ensure that they have permission (i.e. a legal basis) for data processing, as this requirement increases users control over their personal dataenabling users to deny permission, or provide it only for specific purposes. Yet, at the same time, this requirement entails costs for the user, who may be subjected to a lengthy and potentially annoying decision process. For some users, the benefits of control over ones data may outweigh the costswhereas for others, the opposite may be the case. 5.1.2 Effects of Documenting and Managing Permissions 5.1.2.1 Effects on Actors in the Online Advertising Industry Regardless of whether the user has granted or denied permission for personal data processing, the publisher must document the request for permission and the users decision. This obligation comes with considerable costs to the publisher, requiring, for example, investments in technological infrastructure, processes, and personnel. To illustrate these documentation costs, consider a publisher such as the German news site Focus Online (www.focus.de). According to assessments by AGOF (a German association of online marketers), Focus Online has approximately 25 million unique monthly users (as of September 2021, www.agof.de/?wpfb_dl=8454). Suppose that, in a given month, the publisher lacks information regarding permission decisions for about 25% of usersfor example, because these users are new, or deleted their cookies. Focus Online then has to request permission from these users and store the information regarding their decisions. This process yields 6.25 million decisions per month (=25% * 25 million users per month * 1 decision per user). Let us further assume that Focus Online collaborates with and therefore transfers personal data to 100 other actors (such as a retargeting agency or an ad exchange)for which it must also request and store each users permission decision (see Section 7 for more information on how these steps are accomplished). Thus, Focus Online needs to request and store 625 million decisions per month (=6.25 million decisions per month and actor * 100 actors) for these actors. Overall, Focus Online needs to document 6.25 million decisions (for itself) and 625 million decisions (for other actors), in total 631.25 million decisions. The online advertising industry, particularly IAB Europe, created the Transparency and Consent Framework (TCF) to support this documentation process. We describe the TCF in Section 7. In addition to the documentation costs, the GDPR induces other costs from processes that we refer to as the management of permissions for data processing. For example, the GDPR endows the user with the rights to understand, change, and restrict personal data processing (Section 4.3). Thus, the publisher needs to enable the user to retract or alter the permission for processing personal data and be able to delete the collected data of a user at any point in time. Subsequently, we outline the resulting costs using the example of a publisher. However, these costs occur similarly to all vendors that process the users data on behalf of the publisher. Returning to our example, let us assume that, in a given month, only 0.5% of all Focus Onlines users retract their permission and request the deletion of their personal data. In this case, Focus Online would need to provide data for 125,000 users (= 0.5% * 25 million users). Suppose this provision is a manual process, i.e., a service or back-office employee individually updates the database for each users data and then sends each user an individual email. Then, the resulting personnel cost would be extremely high. For example, assuming a minimum duration of 3 minutes per user, the resulting total duration of this work would be 375,000 minutes (=125,000 users * 3 minutes per user), i.e., 6,250 hours, equivalent to 260 days or 8.5 months of non-stop work just to respond to all requests from one month. In a country like Germany, where the gross minimum wage per hour in 2021 is 9.50, the corresponding gross cost for personnel is equal to 59,375 per month, or 712,500 per year. These estimates represent a lower bound, given that the calculation was based on the minimum wage and neglected non-wage labor costs such as health insurance. Therefore, it seems beneficial for firms to invest in processes and IT infrastructure that automate the described process. The fashion retailer Zalando is an example of a firm that enables users to submit an online request for information about and deletion of their stored data, as Figure 11 illustrates. Notably, even this technologically advanced retailer outlines that it can take up to 30 days (the maximum allowed duration) to provide a user with the stored data. Thus, it is evident that a publisher might incur immense costs to comply with the users right to information. Overall, we can conclude that the GDPR has induced new and substantial costs for the online advertising industry. Figure 11: Example of a Data Request (here Zalando) 5.1.2.2 Effects on the User Documenting all firms that collect the users personal data is crucial for enabling the user to exercise full control over these data. Assume, for example, that a user decides to apply online for new health insurance. Some online insurance providers might have already tracked the user online and targeted the users with ads. The user may, at one time, have granted permission to the various health-related publishers to process her data, e.g., for the purpose of receiving personalized content. The insurance providers can use the data that was previously collected for advertising to tailor their offers (ONeil 2016), e.g., set the price of the offer. Such data might include, for example, the health-related publishers the user visited, which exact content the user viewed, and on which health-related ads the user clicked. But now, before the health insurance application, the user wishes to retract the permission and have the collected data deleted. Therefore, the user needs to know precisely which health-related publishers collected her data and which other actors were involved in the data processing, i.e., which other actors also got access to the data. Assume that 10% of all unique publishers the user visits are health-related. If we further assume that the average user visits 50 unique publishers per month, then the user is estimated to visit 5 unique health-related publishers per month (= 10% of health-related publishers * 50 unique publishers). If each of these publishers has connections to 100 other actors, the user would need to keep a monthly record of 5 publishers and 250 other actors (=5 publishers * 100 other actors per publisher of which 50% overlap). Thus, we conclude that the user also faces high costs for managing her permissions. 5.2 Effects Dependent on the Outome of the Users Decision We continue by outlining how users decisions to grant versus deny permission for data processing affect firms operating in the advertising industry, as well as the users themselves. We focus on two extreme cases: the case in which the user grants permission for all personal data processing (e.g., chooses the accept all option in response to a cookie banner); and the case in which the user denies permission for all personal data processing (e.g., chooses the deny all option). 5.2.1 Effects of Granting Permission 5.2.1.1 Effects on Firms Operating in the Online Advertising Industry If a user grants the publisher permission for all processing of personal data (e.g., by choosing the accept all option), then the publisher (and other actors with which it collaborates) can track, profile, and target the user for the purposes the publisher has specified. This level of access is similar to what the publisher would have been able to achieve before the GDPRwith the difference being that the publisher has the users informed permission to engage in its data processing activities, and has made these activities more transparent to the user. Indeed, in this case, the publisher has a legal basis that supports the lawfulness of its personal data processing activities, in accordance with the GDPRs specifications. Given the many advantages that the online advertising industry derives from tracking, profiling, and targeting, an advertiser will likely prefer to display ads with a publisher where users can be tracked, profiled, and targeted rather than with a publisher for which these practices are not possible. Thus, the publisher gains a competitive advantage from having a large share of users who provide consent to tracking, profiling and targeting. The percentage of users who permit such activities is referred to as the publishers consent rate (in %). 5.2.1.2 Effects on the User A user who chooses the accept all option receives targeted ads and personalized content. Such personalization enhances the likelihood that the user will be exposed to ads and content that are relevant, i.e., aligned with her interests (Boerman et al. 2017). Increased relevance of ads and content, in turn, improves the users online experience. Personalization of ads and content comes at a certain cost to users. First, when more firms have access to a users personal data, the risk of potential misuse of the data increases. Moreover, if the user wishes to actively keep track of the firms that process his datae.g., so that he will be able to delete the data later onthen any provision of consent translates into additional effort that the user must invest. Recall, however, that the user grants or denies consent on a case-by-case basis to each publisherand thus can mitigate these concerns, to some extent, by selecting the individual publishers to whom he wishes to grant the opportunity to feature targeted ads and personalized content. For example, such consent may benefit the user when he visits publishers that provide content directly related to his hobbies (e.g., travel magazines) but may be less useful on other types of websites. 5.2.2 Effects of Denying Permission 5.2.2.1 Effects on Actors in the Online Advertising Industry If a user chooses to deny consent for any data processing, the publisher (and other actors with whom the publisher collaborates) cannot track, profile, or target the individual user. The inability to track users limits advertisers activity (in comparison to the situation pre-GDPR, or, alternatively, situations in which users provide consent). For example, the advertiser cannot retarget the usera term that refers to displaying ads to users who have previously visited an advertisers website without purchasing. Moreover, the advertiser has no information about which ads a user saw in the past. Thus, the advertiser is not able to conduct recency or frequency capping and cannot learn about the users interactions with specific ads at different points in time, for example, for attribution modeling. Consequently, advertising along the specific customer journey of a user is almost impossible. At best, the advertiser can target groups of users, such as in contextual targeting or when advertising at different points in time. The inability to target users is likely to diminish the performance of the advertisers ads and to increase ad wastage. These effects, in turn, may (i) diminish the advertisers willingness to pay for online advertising; and (ii) provide the advertiser with an incentive to shift its budget to other types of advertising. These reactions ultimately decrease ad prices. Empirical evidence suggests that ad prices are 40%-50% lower for users for whom tracking is disabled, as compared with users for whom tracking is enabled (Johnson, Shriver, and Du 2020; Laub, Miller, and Skiera 2022). Lower ad prices imply less revenue for the publishermeaning that the publisher has fewer means to finance the websites content. Consequently, the publishers content quality decreases, potentially attracting fewer users (Shiller, Waldfogel, and Ryan 2018). This decrease in the number of users, in turn, reduces the number of ad impressions that the publisher can sellfurther diminishing the publishers ad revenue. However, viewing fewer ads, for example, by blocking some ads using an ad blocker but allowlisting others, can lead to a higher news consumption (Yan, Miller, and Skiera 2022). There are notable examples of publishers that increased their revenue without user-tracking, such as Netherlands public broadcaster (Nederlandse Publieke Omroep (NPO)). In essence, NPO draw benefits from two developments when refraining from third-party tracking technologies. First, they improved their contextual targeting capabilities, which attracted advertisers to buy NPOs ad inventory even without user-tracking. Second, they cut out ad tech vendors that were involved in user-tracking and behaviorally targeted ads. Thus, NPO managed to increase their revenue without requiring the consent of the users. However, the well-documented empirical results of Johnson, Shriver, and Du (2020) and Laub, Miller, and Skiera (2022) point in a different direction. A lack of permission to track users may further diminish the attractiveness of the publishers contentand thereby decrease its user basebecause of the publishers inability to (i) personalize the content of the website (e.g., by personalizing the content ranking) and (ii) measure the success of the websites content for an individual user (e.g., Ho and Bodoff 2014). For example, without permission for tracking, the publisher can no longer observe when and where a user leaves the website and make improvements to retain the users interest. Together, these effects indicate that a users denial of permission for personal data processing resulting from the GDPRs requirement for a legal basis for data processinginduces a threat of revenue loss for actors in the advertising industry. In particular, the advertiser experiences more ad wastagethough it may be able to offset such wastage by paying lower ad prices. The publisher, in turn, suffers a loss, with the precise effect largely depending on the consent rate of the publisher. In other words, the publisher is more affected by the GDPR than the advertiser, and the publisher is the actor with a greater interest in obtaining the users permission for tracking. 5.2.2.2 Effects on the User For the user, an obvious consequence of denying consent for personal data processing is exposure to non-personalized content and adswhich may be less relevant to the users interests compared with personalized content and ads (which the user would be more likely to have viewed before the GDPR, when tracking was the default). A consequence that is less obvious for most users is the possibility of a decrease in the quality of free online contentas a result of lower ad revenues, according to the logic outlined above. Publishers might further respond to decreasing ad revenues by charging for their content, or by adopting innovative approaches such as so-called cookie paywalls (referred to by some German and Austrian publishers as the PUR model)which offers users a choice between either accepting the websites tracking or paying for a tracking-free (and sometimes even ad-free) version of the website (Müller-Tribbensee, Miller, and Skiera 2022). The PUR model has gained popularity, especially among content providers such as the news website Washington Post (see Figure 12). Yet, it is not entirely clear whether this model is compatible with the GDPRs requirement that, to serve as a legal basis for tracking, the users consent must be freely given (meaning that the users capacity to access a website cannot be contingent on the provision of consent). Indeed, requiring the user to accept tracking in order to access free content seems to negate the idea of freely given consent. Yet publishers might argue that the user is, in fact, free to make a choiceas she can access the content while still avoiding tracking by paying the publishers stated price. Some Data Protection Authorities, such as the ones in Austria and in Hamburg, have decided that the PUR model is valid as long as the price for the content is reasonably low. In this case, the user is considered to have a choice between paying with data or with money for the publishers content. Figure 12: Example of the PUR Model (here: www.washingtonpost.com) Several industry actors have proposed an alternative model in which, instead of paying to access a publishers website with data or money, users sell the rights to process their personal data, i.e., allow tracking, in exchange for money. For some users, this approach could be an attractive alternative to denying permission. A significant obstacle to this approach is that the user typically does not know the datas value (Lischka and Kenning 2020). Moreover, the opportunity to sell data in exchange for money is not universally available; firms adopting this model have begun to emerge only recently. We discuss industry initiatives that picked up this approach and tackled these obstacles in Section 9.1. 5.3 Main Takeaways The main takeaways from Section 5 are: The requirement for a legal basis for data processing in the advertising industryin the form of either explicit permission (consent) for data processing or implicit permission (legitimate interest)provides users with more control over their personal data, enabling them to determine how much tracking, profiling, and targeting to allow, if any. Yet this benefit comes with costs for actors in the advertising industry, as well as for the users themselves. Regardless of whether users provide or deny permission for data processing, publishers face high costs for requesting such permission (e.g., through cookie banners) and managing information on users decisions. The very need to decide whether to provide permission, as well as to track and manage such decisions, also entails costs for users, which may worsen the users online experience. If the user grants (as opposed to denying) permission for data processing, the user likely receives ads and content of higher relevance, but shares more personal data with a variety of firms, which represents a loss of privacy. If the user denies permission, the advertiser has less data to improve online advertising performance and becomes less willing to pay for online advertising; the publisher, in turn, faces a threat of lower revenue from online advertising to finance its free content. Thus, a high consent rate represents a competitive advantage for a publisher; the quantity and quality of the content that the user can access for free may be lower than they would have been had the user provided permission. "],["consent-management-tools.html", "Section 6 Consent Management Tools 6.1 Consent Management Platforms (CMPs) for the Online Advertising Industry 6.2 Software for the User 6.3 Main Takeaways", " Section 6 Consent Management Tools In the previous section, we discussed how the GDPRs requirement for a legal basis for data processingwhich, for actors in the advertising industry, implies a need to get the users explicit or implicit permission for data processingentails costs to both publishers and users. In what follows, we elaborate on tools that have been developed to mitigate these costs. For the publishers, there are Consent Management Platforms (CMPs), which is software often combined with services, and for users there is software, often in the form of a browser extension. 6.1 Consent Management Platforms (CMPs) for the Online Advertising Industry A CMP is software that provides publishers with technical support in obtaining and managing users permissions with regard to data processing. It also centralizes information about users permissions, such as when, where (on which website) and what permission occurred. Table 7 illustrates the core functionalities of a CMP (Gradow and Greiner 2021). Though some publishers implement and run their own CMPs in-house, others rely on external firms, called CMP-providers, that implement and run CMPs for them. Table 7: Core Functionalities of a Consent Management Platform (CMP) 6.1.1 Use of CMPs for Requesting User Permission for Data Processing A CMP provides publishers with the technology to create and display a request for permission, in the form of a cookie banner that is displayed to the user. Some CMP-providers offer various additional services for enhancing the request for consent. First, some CMP-providers offer A/B testing to optimize the design of the cookie banner, so as to increase the likelihood of obtaining the users consent. Such optimization includes testing variations in design elements such as the position of the banner or the color scheme, as well as variations in the text used to lead the user towards accepting tracking. On the basis of its experience with various publishers, the CMP-provider gains crucial knowledge about optimal cookie banner designknowledge that enhances the value of its services and makes it an essential actor in the online advertising industry. A second service that CMP-providers offer is the detection of hidden trackers. Under the GDPR, the publisher must inform the user about, and obtain permission for, all tracking activities on its website. Yet, the publisher might not be aware of all implemented trackers. Specifically, some trackers, called piggyback trackers, hide within other trackers. For example, a third-party cookie on publisher As website might have a connection to another third-party cookie that publisher A is unaware of. If publisher A fails to get permission for the activities of this hidden tracker, it will be in violation of the GDPR and risk incurring high fines. CMP-providers that detect hidden trackers enable publishers to avoid this risk. Third, CMP-providers can integrate different legal frameworks into the CMP and thus enable the CMP to adjust the cookie banner to the users location dynamically. A CMP can, for example, use the location of a user to detect which privacy law appliese.g., the GDPR or the CCPAand can adjust the request for consent (i.e., the cookie banner) accordingly. In doing so, the CMP can help the publisher to comply with privacy regulations worldwide. 6.1.2 Use of Consent Management Platform (CMP) for Managing Permission In addition to supporting publishers in requesting permission, the CMP provides the technology to store, in a structured manner, information about a users decisions in response to permission requests, alongside information about the cookie banner variant to which the user was exposed. This structured storage facilitates the process of managing the users permissions in several ways. First, it enables the publisher to easily exchange information about the users permissions with other involved parties. If, for example, publisher A uses the service of firm B for the analysis of individual click-through rates, then firm B acts as a data processor on behalf of publisher A. Firm B is only allowed to analyze the data if the user explicitly consented to this activity. Therefore, publisher A and firm B need to exchange information about the users permissions regarding personal data processing. Second, the structured storage inherent to the CMP provides a technological interface for the user to update or retract permission. By law, the user has the right to retract permission for data processing at any point in time. Therefore, many CMPs enable the publisher to embed a link on its website that opens the cookie banner again (in many cases, this link directs the user to the second layer of the cookie banner), or that activates a user interface that offers the possibility to alter permissions for data processing. Figure 13, for example, outlines the implementation of such a link on the website of Bloomberg Europe. The link opens the second layer of the cookie banner of the website directly. Figure 13: Managing Cookie Settings at Bloomberg.com A third means by which the CMP facilitates consent management is by creating a so-called consent log containing a history of all events related to the users permission decisionsincluding the initial decision and subsequent changes. Such a consent log is helpful in documenting and retracing the history of a users decisions with regard to consent (Figure 14). An entry to such a log file consists of at least three elements: an identifier, such as an anonymized IP address, a time-stamp, and the activity that the user performed, such as selecting the accept all option on the cookie banner. Figure 14: Example of a History of a Users Decisions on Permission for Personal Data Processing. Source: www.didomi.io/de/plattform/berichten-kontrollieren This consent log offers several benefits. First, it provides the publisher with proof of its legal basis for data processingi.e., the users consentif needed, for example, for compliance audit purposes. Second, it allows the publisher to analyze when a user gave or retracted permission for various data processing activities. For example, a user might provide publisher A with consent for behavioral targeting for advertising and retract the consent for behavioral targeting at a later point in time. Combining data from the consent log file with data about delivered ads could then help the publisher understand which advertising might have led to the retraction of consent. 6.2 Software for the User The users challenge when browsing online is to decide on and respond to each websites initial request for permission, keep track of all decisions and update the decisions if desired. Researchers from academia and industry started to develop, often in cooperation, so-called Personal Information Management Services (PIMS). The underlying vision of most PIMS is the provision of a tool that centralizes all information regarding a users data and enables the user to manage all in and outflow of the users data in one place. The scope of these PIMS is usually beyond mere consent decisions and often includes all sorts of data, including data from social media such as Instagram, LinkedIn or Twitter. Many PIMS aim at automatically detecting and responding to data requests, such as consent requests. In such a case, the user only needs to provide her privacy preferences once in the PIMS and update it if the privacy preferences of the user change. Such an update then automatically notifies and updates all other actors that process the users data. Automating requires synchronization between the users PIMS and data controllers and data processors from the industry. This synchronization poses several challenges, such as establishing connections between all the involved actors and a common technical language. At this point, many technical and legal challenges persist, such as whether the PIMS should save the users data in the cloud, which facilitates synchronization among actors, or locally on the users device, which usually offers higher data security. Given the various challenges, most PIMS are still under development. Currently, users mainly have access to a few tools providing a basic version of a PIMS and focusing on consent decisions. These tools are browser extensions, available free of charge, primarily for Google Chrome and Mozilla Firefox. Subsequently, we describe them in more detail. 6.2.1 Use of Browser Extensions for Making Decisions on Permission The few browser extensions that assist the user in deciding on permissions for data processing either block cookie banners or automatically respond to requests for permission for personal data processing. Using a browser extension that blocks cookie banners means that the user does not grant permission for any data processing activities. In other words, legally, the user is a deny all user. On some websites, the user appears technically with an unanswered request for permission, which can interfere with website functionality. Among browser extensions that respond automatically to cookie banners, some block all cookies, whereas others provide minimal consent, i.e., they only allow first-party cookies that are required for the website to function (= functional cookies). A significant problem with these automatic responses is that specifications of consent differ widely across cookie banners. Some rely on the function that cookies fulfill (e.g., functional cookies, analytics cookies, marketing cookies), some use the Transparency and Consent Framework (TCF)a framework developed by IAB Europe for obtaining consent (described in detail in Section 7); and the rest use other specifications. Thus, even if a browser extension is informed of the users preferences, it might not be able to respond appropriately to all websites specifications. A notable example of a very promising browser extension is the advanced data protection control (ADPC) browser extension, which offers advantages for publishers and users. ADPC is a joint project of the consumer protection agency NOYB (Section 9.4.1) and the Sustainable Computing Lab at the Vienna University of Economics and Business. ADPC allows publishers to request permission either using the TCF or formulating specific permission requests, making ADPC interoperable with other systems. It allows users to set general signals, e.g., object to all, to set specific signals, e.g., consent to a specific request, or to combine general and specific signals, e.g., reject all, but consent to requests A and D. It allows users to either set global options that apply to all publishers or set publisher-specific preferences (www.dataprotectioncontrol.org). ADPC is still under development, and a prototype is available in the browsers web store. As of November 2021, ADPC has 145 Chrome users. The most downloaded browser extension, I dont care about cookies, sometimes accepts all and sometimes accepts only necessary cookies, depending on what is technologically easier to execute for the extension. The popularity of this browser extension (more than 600,000 downloads for Chrome as of November 2021) might indicate that many users prefer not to receive a cookie banner when visiting a website, and are willing to forgo the opportunity to make a differentiated decision regarding their permission preferences. The use of these tools entails certain disadvantages. First, these tools begin to operate before a website loads, thereby increasing the sites loading time and, in some cases, even preventing loading altogether. These effects likely worsen the users online experience. Another concern is that some users might lack the technological sophistication needed to seek out these tools and install them. A lack of technological expertise among users could explain why the download numbers of the browser extensions are relatively low. Indeed, as of November 2021, most consent management-related browser extensions for Chrome have fewer than 1,000 downloads each. Only a few browser extensionse.g., Consent-O-Matic or Consent Managerhave up to 10,000 downloads. The only browser extension with a truly substantial number of downloads is I dont care about cookies, mentioned aboveyet the 600,000 users who downloaded this extension are still a relatively meager group, given that the EU has about 400 million Internet users, and Chrome has a market share in Europe of 60%. 6.2.2 Use of Browser Extensions for Managing Permissions For the user, managing permissions entails keeping track of each decision made to grant a website permission for data processing. A basic tool for this purpose would list all permissions that the user provided. However, to the best of our knowledge, no browser extension or other tool exists to provide this service. Some browser extensions support the user in making initial permission decisions and document websites where the user blocked cookies or cookie banners. Major web browsers keep a record of installed cookies that users can access, enabling users to delete all or certain cookies. With the development of PIMS, we will likely see such tools in the future. Sophisticated versions could also enable the user to request information about the data stored on a particular website (Section 4.3.1) and request the deletion of the data. 6.3 Main Takeaways The main takeaways from Section 6 are: CMPs help actors in the online advertising industry obtain and manage user permissions, towards supplying a legal basis for personal data processing. CMP-providers provide publishers with services, alongside several additional benefits (e.g., cookie banner optimization), and have thus emerged as a new and important actor in the online advertising industry. Only a few tools are currently available that help users make and manage decisions on permissions. These tools have certain disadvantages, including increasing page loading time, and some even conflict with website functionality. "],["getting-user-permission-for-personal-data-processing-via-the-transparency-and-consent-framework-tcf.html", "Section 7 Getting User Permission for Personal Data Processing via the Transparency and Consent Framework (TCF) 7.1 Challenges of Getting Permission 7.2 Transparency and Consent Framework (TCF) 7.3 Mitigating Challenges in Specifying Purposes for Permission 7.4 Mitigating Challenges in Handling Permission 7.5 Mitigating Challenges in Checking Permission for Data Transfer 7.6 Main Takeaways", " Section 7 Getting User Permission for Personal Data Processing via the Transparency and Consent Framework (TCF) In this section, we delve further into the practical challenges that firms in the advertising industry face in supplying a GDPR-compliant legal basis for their data processing activities. In particular, this section elaborates on the Transparency and Consent Framework (TCF), an industry initiative launched by IAB Europe for assisting firms in addressing the challenges for getting user permission. We note that, in practice, the process of ensuring the GDPR compliance is similar for the two legal bases that are applicable to the advertising industry, namely, (i) a users explicit consent, or (ii) legitimate interest for processing data (see Section 4.5 for a detailed discussion of these legal bases). In both cases, the firm must get the users permission for data processing, with the difference being that reliance on consent requires the user to opt-in to data processing, whereas reliance on legitimate interest requires the user not to opt-out. For convenience and for clarity of presentation, in what follows, we generally address consent and non-objection to legitimate interest simultaneously, using the term permission to refer to both of these concepts. 7.1 Challenges of Getting Permission To get a users permission for personal data processing, a firm has to take the following three steps: (1) specifying the purposes of data processing for which permission is being provided (Section 4.4.4); (2) handling the permissionwhich includes both asking for permission and storing permission; and (3) checking the permission for data transfer, i.e., verifying that any transfer of data to other firms is carried out in accordance with the permissions that the user has provided. A firm faces challenges in each step. Table 8 provides an overview of the three steps, the actions that each step entails, and the corresponding challenges, which we discuss in detail in what follows. Note that in Table 8 and throughout this section, we use the term vendors to refer to other actors (see Section 2.4), in accordance with the terminology used by the TCF. Table 8: Steps, Actions, and Challenges in Getting User Permission for Personal Data Processing towards Supplying a Legal Basis under the GDPR 7.1.1 Challenges of Specifying Purposes for Permission Step 1 (specifying purposes for permission) describes how a firm tries to comply with Article 5 para. 1 point (b) of the GDPR: Personal data shall be collected for specified, explicit and legitimate purposes. In other words, in this step, the firm must identify legitimate purposes for using the processed data and specify these purposes in a clear (explicit) manner. Moreover, according to Article 13 para. 1 of the GDPR, a firm needs to communicate the specified purposes with its users. Notably, it must specify and communicate the purposes of data collection not only on its own behalf but also on behalf of all firms to which it transfers users personal data, and it must also identify these firms (Article 13, para. 1, point e): the data controller shall [inform the data subject about] the recipients or categories of recipients of the personal data, if any. The GDPR itself does not define which specified, explicit and legitimate purposes are acceptable, leaving room for interpretation. Consequently, it is possible that ten different firms will come up with ten different ways to specify their purposes. For example, Firm A might specify and label two purposes: (1) cookies for payment information; (2) tracking users behavior online. Meanwhile, Firm B might specify the same two purposes but label them differently from Firm A: (1) cookies to process payment; (2) cookies monitoring users online. If these two firms were to collaborate, the two different labels would make it challenging to match these two purposes automaticallythough the purposes are effectively identical. In addition, the specifications can also differ substantially. Thus, the potential for heterogeneity in purpose specification makes communication to users and between firms challenging. In light of the above, we suggest that firms face three major challenges in the step of specifying purposes for data processing activities (Table 8): namely, specifying purposes in a manner that is (1) accurate, (2) explicit, and (3) convenient to communicate with users and other firms. Challenge 1: Accuracy. In order to achieve accuracy, a firm must specify the purposes of data collection in a manner that is both GDPR-compliant and commonly accepted, thereby reducing the likelihood of misunderstanding.Achieving accuracy is challenging because the definitions and rules in the GDPR (Section 4) are abstract and open to interpretation. Indeed, there are disparities in interpreting the GDPR compliance among the Data Protection Authorities themselves.For example, the Data Protection Authorities of the UK and Spain require that analytic cookies get consent, while Germany disagrees, and France as well as Italy allows for several exceptions (Voisin et al. 2019). Hence, it is difficult for a firm to find a GDPR-compliant specification that is robust to all interpretations. Another aspect that makes accuracy challenging is the possibility of heterogeneous specifications of similar purposes, as in our previous example of Firm A and Firm B. Suppose that Firm A transfers data to Firm B. In order for this transfer to take place, both firms must ensure that they have user permission for the two purposes specified by Firm B. Due to the different labels, Firm B may find it challenging to decide whether the purposes specified by Firm A accurately match its own specified purposes. Challenge 2: Explicitness. The GDPR requires that a firms data collection activities be made explicit, i.e., fully transparent to the user. However, the GDPR does not indicate the exact information that firms must provide in order to achieve sufficient explicitness.Accordingly, firms face the challenge of identifying which information will provide users and other firms with a sense of explicitness. Challenge 3: Convenient Communication. Convenient communication entails using wording that reduces the chances of misunderstanding, while remaining concise and easily accessible to users and other firms.Again, because the GDPR does not specify which wordings should be used to describe the various purposes of data collection, it is challenging for a firm to identify the optimal wordings in this regard. In particular, firms may face a trade-off between using more words to achieve accuracy and making the text concise and accessible (Kulyk et al. 2020). 7.1.2 Challenges of Handling Permission As shown in Table 8, step 2 of getting permission (handling permission) consists of two actions: asking for user permission and storing user permission. We note that Section 5 provides additional discussion of these actions alongside the costs that they might inflict on firms and on users, and Section 5 provides information on technological tools used to mitigate these costs. Action 1: Asking for Permission. This action involves a publisher asking for the users permission to have her data processed for the purposes that the publisher has specified. A publisher relies on a cookie banner to ask for the users permission (Section 5). A users positive response to the publishers request implies that the publisher has obtained permission to process the users personal data. As discussed in previous sections, asking for user permission can be challenging for a publisher because designing and running a cookie banner on web pages requires technical knowledge that some firms lack (Section 5.1.1.1). Moreover, a publisher must ask for permission on behalf of all the vendors to which it transfers user data for processing, as these vendors do not have direct access to the user. It may be challenging for a publisher to centralize its vendors heterogeneous requests for permission, as different vendors may have different specifications for purposes (as discussed in Section 7.1.1). Action 2: Storing Permission. After asking a user for permission, the publisher must locally store information about the users responsenamely, whether the user has given permission for each specific purpose corresponding to each vendor. By storing this information, the publisher can avoid re-requesting the users consent each time the user visits its website. Storing permission can be challenging in two ways. First, the publisher has to find a way to encode and store the users decisions in a small amount of space. Indeed, a users granular decisions on permissions can form massive amounts of information. Publishers pass this information via HTTP requests throughout the chain of data transfer. Since there is a size limit for such requests, a publisher has to store permission information compactly. Second, it is challenging to store permission information in a way that enables vendors to access and read the information in a manner that is not excessively costly. Indeed, a vendor may incur high costs to access stored permission information, particularly when it transfers such information to other vendors. Recall that a vendor has to rely on a publisher to ask for permission on its behalf. Suppose Vendor A transfers data to Vendor B; Vendor A has to access the publishers permission information to see whether Vendor B has received user permission. This process can become costly if Vendor A transfers data to many other vendors (Figure 5) and has to contact the publisher repeatedly. In addition, if a vendor works with multiple publishers that store information in different ways, it incurs costs associated with reading various storage formats. Aside from the challenges outlined above, publishers face challenges in keeping stored permissions up to date. In effect, these challenges relate to the need to integrate the action of asking for permission with the action of storing permission. Suppose a user updates her permission settings and revokes permission that she granted in the past for a particular purpose. The publisher needs to update the permission information for each actor, and to ensure that all involved actors have the same, current information at the same point in time. To achieve this goal, it is necessary to integrate cookie banners with storage and data processing systems. Such integration poses both technical and legal challenges to firms. Specifically, a firm needs an information technology expert to execute the technical aspects of the integration, and it also needs a lawyerone who is also comfortable with information technologyto verify that the procedure is compliant with the GDPR. Such interdisciplinary talents are rare and expensive to hire. 7.1.3 Challenges of Checking Permission for Data Transfer Step 3 (check permission for data transfer) describes the obligation for a firm that transfers data to other parties. Before Firm A (sender) transfers data to Firm B (receiver), Firm A has to identify Firm Bs purposes for processing and verify that Firm B has permission to process the users data for these purposes. Carrying out this action is challenging. As discussed in Section 7.1.1, the GDPR offers firms the flexibility to specify their own purposes for data processing, and different firms may specify similar purposes in different ways. This diversity in specification increases the time and effort involved in the collaboration between firms. Furthermore, it may be challenging for both firms to argue that their purposes are indeed identical. This challenge is further complicated by the specific roles fulfilled by the firms involved in the data transfer. For example, in a publisher-to-vendor data transfer, a publisher has to handle user permission on behalf of a vendor, and then check whether the permission it has obtained is indeed applicable to the purposes that the vendor has specified. This procedure, entailing multiple responsibilities imposed by the GDPR, is highly complicated. Similarly, in a vendor-to-vendor data transfer, the data-sending vendor always has to check with the publisher whether the data-receiving vendor has user permission. This process can entail substantial effort, particularly when the vendor collaborates with many other vendors, as illustrated in Figure 5. 7.2 Transparency and Consent Framework (TCF) On April 25, 2018, IAB Europe launched the TCF as a means of tackling the challenges discussed in Section 7.1. It launched an updated version of the TCF, TCF 2.0, in August 2019. The TCF is an industry initiative, aiming at providing a solution to get user permission with guidelines and tools. In order to adopt the solution, a firm has to register with IAB Europe, denoted as participating in TCF in the following sections. The TCF was formulated on the basis of extensive consultation with representatives from different fields in the online advertising industryincluding technology vendors (Xandr), CMPs (OneTrust), and publishers (The Telegraph). Specifically, the TCF aims to introduce a standard that - creates a standardized terminology of purposes shared by all participants; - provides tools to facilitate asking for permission (Global Vendor List) and storing permission (Transparency and Consent String); and - creates a procedure to check permissions for processing personal data before transferring user data between firms. Note that each bullet point corresponds to one of the three steps described in the previous section, and summarized in Table 8: specifying purposes for permission, handling permission, and checking permission for data transfer. In what follows, we provide a step-by-step explanation of how, in practice, a firm can use the TCF to execute each of the three steps and overcome the associated challenges. The TCF was envisioned as a well-documented and accepted standard that should help firms to comply with the GDPR. A Canadian initiative (www.iabcanada.com/transparency-and-consent-framework) builds upon the idea of the European initiative. Yet, the Irish Council for Civil Liberties suspects that the TCF infringes the GDPR. We will discuss their concerns in more detail in Section 9.4.2. 7.3 Mitigating Challenges in Specifying Purposes for Permission 7.3.1 Facilitating Accuracy of Communication 7.3.1.1 Purposes As pointed out in Section 7.1.1, as the GDPR does not define precisely what a specified, explicit and legitimate purpose is, a firm may find it difficult to specify purposes that are GDPR-compliant under the interpretations of all parties, as well as to match its own purposes to those of other firms (in the case of data transfer between firms). To overcome these challenges, the TCF proposes ten specific purposes, which are shown in Table 9. Table9: Specification of Purposes in the Transparency and Consent Framework (TCF) 2.0 TCF uses the term Purpose to refer to each of the ten purposes specified in Table 9. To avoid confusion, throughout the remainder of this section, we refer to Purpose specified by the TCF as a TCF purpose and refer to a specific TCF purpose (e.g., Purpose 2) as Purpose N where N is an integer from 1 to 10. Seven of the ten TCF purposes relate to either advertisement (Purposes 2, 3, 4, and 7) or content (Purposes 5, 6, and 8). Moreover, the purpose specification structures for advertisement and for content are similar. Notably, for Purposes 210, a firm can claim either consent or legitimate interest as the legal basis for data processing. For Purpose 1, howeverwhich does not indicate a broader motivation for data processing but instead refers solely to the act of storing or accessing information on a devicea firm cannot claim legitimate interest and must obtain explicit consent. The motivation for including Purpose 1 in the list of TCF purposes is that it corresponds to the obligation of Article 5 (3) of the ePrivacy Directive (relevant for the Planet49 decision of the European Court of Justice). Article 5 (3) emphasizes the importance of getting user consent for storing information. Purpose 1 is unique because data controllers cannot pursue Purpose 1 on its own but rather only in conjunction with another TCF purpose, which is an unavoidable logical outcome. For example, if Google wishes to display an ad to a userwhether personalized (Purpose 4) or non-personalized (Purpose 2)it must obtain consent for Purpose 1. If the user denies consent for Purpose 1 but accepts consent for Purpose 4 and Purpose 2, Google will still drop the ad request and serve no ad, regardless of whether the ad is personalized or not (Roth 2020). The reason is that Google relies on cookies or mobile identifiers for both non-personalized ads (e.g., for frequency capping or fraud detection) and personalized ads (targeting). The example of Google further highlights the importance of Purpose 1. Note that data processors might still need Purpose 1 but not any of the other TCF purposes because they rely on the legal bases established by their data controllers. Moreover, data controllers may also declare one or more Purposes 2-10, without declaring Purpose 1 if they do not need access to the device. With the help of the ten TCF purposes, all firms using TCF can communicate accurately with one another. For example, when a firm mentions Purpose 4, every other firm knows that the firm is referring to selecting personalized ads. We note that the specifications outlined in Table 9, corresponding to ten TCF purposes, reflect TCF 2.0, which launched in August 2019. TCF 1.0 (launched in April 2018) contained only five purposes. TCF 2.0 made the purposes more granular, in accordance with the WP259 guideline on consent (European Data Protection Board 2020). The guideline points out that granularity is an element of valid consent. This adjustment to conform to legal guidelines reflects that the TCF has been improving and revising its purpose specifications. 7.3.1.2 Special Purposes In addition to the ten TCF purposes outlined above, the TCF specifies two Special Purposes, defined as purposes that firms must fulfill in order to technically be able to serve ads. Table 10 contains the two Special Purposes stipulated in TCF 2.0. Legitimate interest is the only legal basis that is applicable to these Special Purposes, and users cannot execute the Right to Object to these legitimate interests (Article 21, GDPR). The reasons are the following. Special Purpose 1 refers to a firms legal responsibilities, so a firm must be allowed to pursue the purpose. Special Purpose 2 is technically necessary for delivering information over the network to an IP address. Although the Right to Object to Special Purposes is not technically supported by the TCF, publishers and their partner vendors can still establish some signaling mechanism to enable the execution of the Right to Object. Table 10: Specification of Special Purposes in the Transparency and Consent Framework (TCF) 2.0 7.3.2 Facilitating Explicitness of Communication 7.3.2.1 Features The TCF further specifies several Features. Features are not purposes in themselves. They are methods to process data related to one or more TCF purposes. Features are technically necessary to achieve certain TCF purposes; once the user has given permission for a particular TCF purpose, she does not need to provide additional permission for the associated Features. Note that a Feature is always linked to a TCF purpose and if there is no legal basis supporting that TCF purpose, the Feature has no meaning. Features require no legal basis, and information about them is provided to the user solely as a means of improving communication explicitness, that is, to provide the user with information about the methods that firms will apply to the users data to achieve the approved (Special) Purposes. Table 11 contains the content of the Features. Table 11: Specification of Features in the Transparency and Consent Framework (TCF) 2.0 7.3.2.2 Special Features Apart from Features, the TCF also contains Special Features. Special Features are similar to Features because firms may use them as a technical means of implementing one or more TCF purposes. However, Special Features are more privacy intrusive than Features are (e.g., precise geolocation), meaning that they relate to processing of data that may be more sensitive to a user. Therefore, a firm can only use the Special Features with consent as a legal basis. Table 12 shows the two Special Features. Table 12: Specification of Special Features in the Transparency and Consent Framework (TCF) 2.0 Figure 15 summarizes the differences in legal bases for Purposes, Special Purposes, Features, and Special Features in TCF. A green cell indicates that a particular legal basis (column) is applicable to a particular (Special) Purpose or (Special) Feature (row). In almost all cases in which a particular legal basis applies, the user has the right to make a decision, i.e., to provide/deny consent, or to accept/object to the legitimate interest. The only exception is for Special Purposes, which are grounded in the legal basis of legitimate interest, and to which the user cannot object. Figure 15: Legal Bases for (Special) Purposes and (Special) Features in Transparency and Consent Framework (TCF) 2.0 7.3.3 Facilitating Convenience of Communication with Stacks To provide firms with a simplified way to ask for permission, requiring users to make fewer decisions without sacrificing granular information or choices, TCF proposes Stackspre-defined groups of TCF purposes and/or Special Features. The TCF 2.0 Policy defines 42 Stacks that a publisher can choose to display on its cookie banner. Table 13 provides an example of a TCF Stack, labeled as Stack 2. If a publisher uses Stack 2, the publisher displays the name of the Stack Basic ads and ad measurement in the first layer of the User Interface (UI). The publisher usually displays the Stack description and corresponding TCF in a further layer, e.g., on a separate page. By choosing Yes for this Stack, a user simultaneously gives consent to Purpose 2 and to Purpose 7. As indicated by some DPAs (e.g., CNIL in France), displaying Stacks instead of TCF purposes improves the convenience of communication between the publisher and the user because the user has to make fewer decisions (just one instead of two decisions in the Stack 2 example). Nevertheless, the TCF still requires publishers to enable granular choices for each TCF purpose. Part of the convenience brought by the TCF might also be that users get progressively used to semi-standardized interfaces and standardized terminology so that they are increasingly efficient in making their choices over time. Table 13: Example of a Stack in Transparency and Consent Framework (TCF) 2.0 Note that different Stacks may contain overlapping TCF purposes. When selecting from the pool of 42 Stacks, a publisher cannot choose Stacks with the same TCF purpose. For example, Stack 2 contains Purposes 2 and 7; Stack 3 contains Purposes 2, 3, and 4. A publisher cannot include Stack 2 and Stack 3 simultaneously, as both Stacks include Purpose 2. If a publisher were to include both Stacks, it might obtain conflicting responses from users, e.g., if a user accepts Stack 2 but denies permission for Stack 3. For the same reason, a publisher cannot present a particular TCF purpose both as part of a Stack and outside of a Stack simultaneously. To sum up, the TCF assists firms in overcoming the challenges associated with specifying purposes for personal data processing. Specifically, it enhances (i) accuracy of specificationby providing a standardized, clearly defined, and granular set of (Special) Purposes; (ii) explicitnessby providing clear descriptions of (Special) Features that are technically necessary for the fulfillment of the specified Purposes; and (iii) convenience of communicationby creating groups of TCF purposes and/or Special Features, called Stacks, which are presented concisely and that enable users to make decisions on multiple TCF purposes simultaneously. Furthermore, the TCF is very clear about the applicable legal basis and possible user decisions for each scenario. 7.4 Mitigating Challenges in Handling Permission The second step in getting permission for personal data processing is handling permission, via (1) asking for permission, and (2) storing permission. There are several challenges a firm faces in these actions (Table 8). The TCF provides tools to mitigate the challenges, which we will introduce in this section. 7.4.1 Facilitating Asking for Permission 7.4.1.1 Global Vendor List (GVL) The requirements that a firm must fulfill under the TCF in order to handle permission for data processing vary depending on whether the firm is a publisher (Section 2.1) or a vendor (Section 2.4). The critical difference between a publisher and a vendor in handling permission is that a publisher has direct contact with a user and asks for permission on its own, whereas a vendor has no direct contact with a user and needs to rely on a publisher to ask for user permission on the vendors behalf. Section 7.1.2 points out that asking for permission is challenging. To obtain permission, a vendor must tell its partner publishers the purposes for which it requires such permission. As a publisher cooperates with many vendors, a publisher has to centralize all the vendors requests for permission. The heterogeneity of vendors and their respective requests makes centralizing vendor permission challenging. Within the TCF, vendors disclose their required purposes uniformly via a registration process. The standardized registration process and the standardized purpose specification introduced in Section 7.3 simplify the challenge of centralizing vendor permission requests. To register with the TCF, a vendor must have a sufficient reputation (e.g., be a member in good standing with some industry associations) and pay an annual fee of 1500. A vendor who registers with the TCF discloses which of the TCF-specified (Special) Purposes and (Special) Features (Table 9 - Table 12) it pursues. At the same time, the vendor also decides which legal basis to use for each of these (Special) Purposes and (Special) Features. When declaring legitimate interest as the legal basis in the GVL, vendors have to attest that they have carried out adequate Legitimate Interests Assessments (LIA) that operate a balancing between user and vendor interests. IAB Europe provides guidance on how to do this. After receiving the registration application of a vendor, IAB Europe verifies the vendors identity and the vendors ability to maintain its service while sticking to TCF regulations. Approved vendors appear on the Global Vendor List (GVL) (www.iabeurope.eu/vendor-list-tcf-v2-0). The GVL is a list of TCF-registered vendors and the respective (Special) Purposes and (Special) Features each vendor uses. The GVL is publicly available via its official website and updated weekly, enhancing each vendors data processing transparency. Note that the verification process conducted by IAB Europe provides no warranty of GDPR compliance. In other words, the TCF does not certify that its approved vendors are entirely GDPR-compliant. From the GVL, a publisher knows what TCF purposes each vendor pursues, and with which legal basis. Then, a publisher chooses the vendors it intends to collaborate with from the GVL (hereafter referred to as partner vendors). By default, the purposes that each vendor pursues according to the GVL apply to all publishers. If a publisher prefers a legal basis for a specific TCF purpose that is different from the one specified by a particular vendor, the publisher can use Publisher Restrictions to modify the way they collaborate. For example, if a particular vendor uses legitimate interest for Purpose 3, a publisher can restrict the TCF purpose and require consent. In this way, a publisher and a vendor can collaborate more flexibly. If a vendor changes the (Special) Purposes and (Special) Features it uses, it needs to update its information provided to IAB Europe. These updates are included in the next weekly update of GVL. By being connected to the GVL, all publishers automatically have access to the most recent version available via their CMPs (which are also registered with the TCF; see Section 7.4.1.2). Yet, suppose the update requires more permissions, because of an additional (Special) Purposes and (Special) Features, an additional vendor, or a change of the legal basis from legitimate interest to consent. In that case, the publisher needs to ask all users again for their permission. To sum up, TCFs registration process and the GVL standardize how a vendor discloses its purposes to publishers. Furthermore, the process and the GVL provide an efficient means for publishers to centralize and manage permissions for their partner vendors. 7.4.1.2 Consent Management Platforms (CMPs) Registered with the TCF To ask for user permission, a publisher needs to equip its website with a cookie banner. As a firm faces technical challenges in designing and running a cookie banner (Section 7.1.1), a publisher relies on a CMP (Section 6.1) that registers with the TCF to assist in designing and running a cookie banner. Like a vendor, a CMP also has to submit a registration application to the TCF and pay an annual fee of 1500. IAB Europe verifies whether the technical operation of a CMP is compliant with TCF regulations. Again, passing the verification does not guarantee complete GDPR compliance for a CMP. If a publisher participates in the TCF, it must use a CMP from the publicly available list of TCF-registered CMPs. A publisher can use a commercial CMP service or register its own (private) CMP. As of November 2021, there are 170 registered CMPs in the TCF. 53 (31%) of them are private CMPs. A TCF-registered CMP provides technical support to design and run a cookie banner. More importantly, only TCF-registered CMPs can create, update and store the Transparency and Consent String, a tool to store consent, which we will introduce in the following subsection. TCF-registered CMPs must follow the TCF guidelines. IAB Europe randomly audits CMPs for proper TCF implementation on publishers websites and can admonish the CMP if violations occur. After three warnings, TCF can suspend a CMP, which means that all the publishers can no longer use the suspended CMP. Thus, IAB Europe creates a strong incentive for CMPs to ensure that the publishers correctly implement TCF when using their service. 7.4.2 Facilitating Storing Permission with Transparency and Consent String (TC String) Storing consent for a user is technically challenging for two reasons. First, there is a lot of information to store. For example, for each purpose of each vendor, a user can decide whether to provide permission for that purpose or not. Second, publishers have to store permission information in a manner that enables vendors to access and read the stored information easily. The TCF created the Transparency and Consent string (TC string) to cope with these two problems. The TC string is a piece of encoded character string capturing and storing all information about a users permission decisions and other privacy preferences for a publisher. The TC string includes (1) (Special) Purposes and (Special) Features of each vendor cooperating with the publisher, (2) status of user permission (consent or non-objection to legitimate interest) to process data per purpose per vendor, (3) metadata and other restrictions (e.g., the time when the TC string was created). Only TCF-registered CMPs can create and update a TC string. All information in the TC string is encoded in a space-efficient manner so as to enable the TC string to be passed between firms via HTTP GET requests with a storage limit. All publishers within the TCF use TC strings to store consent. All publishers and vendors rely on the Application Programming Interface (API) of a TCF-registered CMP to decode and read TC strings. Thus, in effect, the TCF enables all firms to speak the same language when transmitting and reading information on user permissions (the TC string). 7.4.3 Integrating Asking for Permission and Storing Permission Combining cookie banners, information storage, and data processing in a harmonized way is challenging because it involves technical knowledge from many fields. The TCF attempts to provide a standardized procedure to integrate these different fields, relying on the components described in previous sections (e.g., TCF specification of purposes, TCF tools to facilitate asking for and storing permission). We describe this TCF procedure in detail with three representative cases summarized in Table 14. For these cases, we assume that one user visits a publisher five days in a row and once a day, and that consent is the legal basis for all pursued purposes. We arrange the cases from simple to complex in chronological order from Day 1 to Day 5. Table 14: Overview of Cases of Asking for and Storing Consent under the Transparency and Consent Framework (TCF) Case 1 is a simple example to help understand how a TC string works. A publisher asks a user for consent on its own behalf and stores consent for the user. Case 2 is a general case describing how a publisher asks for and stores consent on behalf of its partner vendor. Case 3 is a case explaining how actors affect each other when having different consent statuses. For example, a vendor may lose access to a users data if its partner vendor does not have the users consent. To make the examples more intuitive, we use figures visualizing how consent information is asked for and stored. 7.4.3.1 Case 1: A Publisher Obtains Consent on its own Behalf Case 1 captures the most straightforward case of collecting and storing consent, visualized in Figure 16. Day 1 describes what happens on the users first visit to a publishers website, and Day 2 depicts the users second visit. On Day 1, User X visits Publisher A for the first time. Publisher A has no partner vendor, so it only needs user consent for itself to pursue its specified TCF purposesin our example, Purpose 6 (select personalized content) and Purpose 8 (measure content performance) (Table 9). Figure 16: Process of Getting Consent under the Transparency and Consent Framework (TCF) for Case 1 When User X arrives at the publishers website (Step 1 in Figure 16), Publisher A contacts its CMP, CMP A, via a CMP tag, a JavaScript tag added to the website of Publisher A (Step 2). Then, the CMP code runs on the page and checks whether a TC string corresponding to Publisher A exists in User Xs local storage (e.g., a first-party cookie) (Step 3). As this is User Xs first visit to Publisher A, no such TC string is found. In such a case, CMP A shows a cookie banner on the website, e.g., as shown in Figure 10. The simplified cookie banner shown in Figure 16 (Step 4) lists out the two TCF purposes covered in our example: selecting personalized content and measuring content performance. Next (Step 5 in Figure 16), User X makes choices on the cookie banner for each purpose, a No for personalized content and a Yes for performance measurement. Then, CMP A creates a TC string for User XPublisher A by encoding the consent information according to the standard (Step 6). Publisher A stores the TC string locally on the device of User X (Step 7). In Step 8, Publisher A relies on its CMP API to decode the TC string. Then, Publisher A knows which purpose User X allows it to pursue, which we visualize in the yellow box of Privacy Preference Information in the center. Eventually, Publisher A can measure content performance based on User Xs data but cannot provide any personalized content to User X. On Day 2, User X visits the publisher for the second time. Steps 1-3 in Figure 16 remain unchanged. Assuming that User X has not deleted local storage since the previous visit, CMP A can detect the previously saved TC string and decode it for Publisher A. In other words, there is no need to show the cookie banner and go through Steps 4-7 again. As long as User X does not change consent information on the privacy policy page, Publisher A will rely on the stored consent information without re-obtaining permission. Overall, asking for and storing user consent in the simplest Case 1 is already a complicated procedure. 7.4.3.2 Case 2: A Publisher Obtains Consent on Behalf of a Vendor Case 2, visualized in Figure 17, captures how a publisher asks for and stores consent on behalf of a vendor. Day 3 describes the first-visit example under the new assumptions, while Day 4 illustrates the second-visit example. On Day 3, Publisher A decides to offer ad slots on its website to monetize its content with ad revenue. Therefore, Publisher A chooses an ad tech vendor, Vendor S, from the GVL as its partner and notifies CMP A about this change. In this example, Vendor S is a Demand Side Platform (DSP) where a publisher lists its advertising inventory for advertisers to buy. Vendor S pursues two purposes with users personal data: Purpose 2 (select basic ads) and Purpose 4 (select personalized ads) in Table 9. Figure 17: Process of Asking for and Storing Consent under the Transparency and Consent Framework (TCF) for Case 2 When User X visits Publisher A, the CMP tag code runs and checks whether a TC string with complete consent information exists. Although a TC string for Publisher A exists, the explicit consent is missing for Vendor S to process User Xs data, as Vendor S has only recently been added. Thus, CMP A shows a new cookie banner to User X. The new cookie banner contains the TCF purposes for Vendor S and Publisher A. To make the illustration concise, we exclude the procedure of acquiring consent for Publisher A itself, which the Case 1 example has already described. User X sees Vendor S and its TCF purposes on the cookie banner and chooses a Yes for basic ad selection and a No for personalized ad selection. In Step 6, CMP A encodes the consent information into a new TC string for User XPublisher A. Then, Publisher A saves the new TC string in the local storage of User X. In Step 8, Publisher A signals Vendor S an ad call via a vendor tag. Before processing User Xs data, Vendor S reads the TC string via the CMP API and knows that it can only use User Xs data to select basic ads. Then, Vendor S serves basic ads to Publisher A for User X in Step 12. On Day 4, User X visits Publisher A once more. In this scenario, similar to the scenario described for Day 2 (for Case 1), if User X has not deleted the TC string in the local storage, Publisher A and Vendor S can rely on the previously saved permissions as given. In other words, no cookie banner pops up, saving Steps 4-7. 7.4.3.3 Case 3: A Publisher Obtains Consent on Behalf of Multiple Vendors Case 3, visualized in Figure 18, captures how a publisher asks for and stores consent on behalf of multiple vendors. Day 5 describes the first-visit example under the new assumptions. On Day 5, Publisher A starts to sell the ad slots via another ad tech vendor, Vendor P, an ad exchange. Thus, Vendor S (DSP) can now only buy ad slots via Vendor P (ad exchange). Both Vendor S and Vendor P use personal data to select basic (Purpose 2) ads and personalized ads (Purpose 4). Again, Publisher A informs CMP A about the recent addition of Vendor P and its TCF purposes. Figure 18: Process of Getting Consent under the Transparency and Consent Framework (TCF) for Case 3 When User X visits Publisher A, Steps 1-3 occur again. As in the scenario described for Day 3 (Case 2), CMP A checks the local storage of User X and finds out that there are vendors and TCF purposes for which the user has not yet provided consent decisions. Therefore, CMP A shows a new cookie banner to User X with purposes and features for Publisher A, Vendor S, and Vendor P. We again neglect the procedures of asking for and storing consent for Publisher A itself for conciseness. Assume that User X ticks Yes for basic ad selection for Vendor S only, and No for the remaining TCF purposes, as displayed in the simplified banner in Figure 18. CMP A encodes the consent information into a new TC string, decoded and interpreted via the CMP API by Publisher A, Vendor S, and Vendor P. When the vendor tag on the website runs in Step 8, Publisher A sends an ad call to Vendor P. However, Vendor P cannot use User Xs data for either of the TCF purposes. Consequently, Vendor S has no access to the data, even though it has user consent for basic ad selection. The dashed grey arrow in Step 12 captures the loss of access to user data. This situation implies that, in Step 14, Vendor S can no longer show a basic ad that, according to the users permission decisions, it would otherwise have been able to show for User X. 7.4.3.4 Example Procedures: Concluding Remarks To keep our example simple and concise, we illustrated the elementary cases of a publisher obtaining consent only on its own behalf, for one vendor, or for two vendors. Even with our simplified focus, the procedures described were quite complexCases 2 and 3 even more so than Case 1. In reality, the complex interplay between publishers and vendors requires the technical solutions for these cases to be even more sophisticated than outlined. The TCF assists in mitigating this complexity by providing actors in the online advertising industry with clear procedures for integrating permission requests and permission storage. Nevertheless, the current TCF procedure cannot take care of every connection in the complex interplay. For example, it is not strictly supervised whether vendors delete the received personal data when a user withdraws her consent or when she wants to have her personal data deleted. 7.5 Mitigating Challenges in Checking Permission for Data Transfer The third step of getting permission for personal data processing is checking permission for data transfer, i.e., ensuring that data-sending and data-receiving firms have permission for identical purposes for transferring personal dataand that the permissions for each purpose correspond to identical legal bases (i.e., consent or legitimate interest). This procedure of matching purpose specifications and legal bases can be technically challenging. TCF attempts to mitigate these challenges by providing standardized checking and matching procedures, which we will introduce in what follows. 7.5.1 Facilitating Checking Permission for Publishers In this section, we discuss the case where a publisher transfers data to other vendors. Recall that a vendor within the TCF discloses, through the GVL, which of the (Special) Purposes and (Special) Features (Table 9 - Table 12) it uses. A vendor also decides which legal basis to use to support each purpose it pursues. A vendor can only support Purpose 1 with consent. To support Purposes 2-10 (Table 9), a vendor has three options: (1) use only consent, (2) use only legitimate interest, (3) use either consent or legitimate interest. For the purposes supported by either consent or legitimate interest, a vendor sets a default legal basis. Then, it is the partner publisher who decides which legal basis to use for the vendor. Note that a firm can only use one legal basis to support one purpose. More formally, for each purpose (Table 9) except for Purpose 1, a vendor has five options: Pursue the purpose and support with only consent as the legal basis. Pursue the purpose and support with only legitimate interest as the legal basis. Pursue the purpose and support with legitimate interest by default, but consent also feasible as the legal basis. Pursue the purpose and support with consent by default, but legitimate interest also feasible as the legal basis. Do not pursue the purpose. Table 15 provides an example of the legal bases for the pursued TCF purposes of a specific vendor (Emerse Sverige AB), who pursues Purposes 19 and does not pursue Purpose 10. The vendor uses only consent to support Purpose 1, Purpose 3, and Purpose 4. The vendor uses only legitimate interest to support Purpose 7 and Purpose 8. The vendor uses either consent or legitimate interest to support Purpose 2 and Purpose 9, and in both cases the default legal basis is legitimate interest. Legal Bases for Purposes under TCF Specification of an Example Vendor (here: Emerse Sverige AB) A publisher has three options for the vendor for each purpose: Desire the vendor to pursue the purpose and support with consent as the legal basis. Desire the vendor to pursue the purpose and support with legitimate interest as the legal basis. Desire the vendor not to pursue the purpose. Given that a publisher has requested permission for data processing on the vendors behalf for a particular purpose, there are four options for the decision that a user can make: In cases in which consent serves as the legal basis: Give consent to process data for the purpose (accept consent). Do not give consent to process data for the purpose (deny consent). In cases in which legitimate interest serves as the legal basis: Accept legitimate interest to process data for the purpose (accept legitimate interest). Execute the Right to Object to legitimate interest to process data for the purpose (deny legitimate interest). Thus, given that a publisher has a relationship with a vendor (i.e., intends to transfer user data to the vendor in accordance with TCF procedures), and given a particular TCF purpose, various outcomes can be obtained with regard to data transfer for that purpose. The outcome depends on the combination of (1) the option selected by the vendor, (2) the option selected by the publisher, and (3) the users decision, given the option selected by the publisher. In particular, seven outcomes are possible (see Figure 19); we classify these outcomes into Deal and No Deal. Deal means that a users personal data are ultimately transferred for processing, while No Deal means that neither data transfer nor data processing takes place. The seven outcomes are as follows: Deal to transfer data upon consent. Deal to transfer data upon legitimate interest. No deal due to mismatched legal basis.  No deal due to mismatched pursuit status. No deal due to no pursuit. No deal due to no user consent. No deal due to users objection to legitimate interest. Figure 19: Outcomes of Actions from a Publisher, a Vendor, and a User When a Publisher Transfers Data to a Vendor In Figure 19, the cells in green represent a successful deal to transfer data from a publisher to a vendor for one of the purposes. The cells in red denote a failed deal to transfer data because the user does not give permission. The white cells represent no deal to transfer data because of a mismatch in the legal basis between what the publisher expects and what the vendor supports for the purpose. The cells in grey denote no deal to transfer data because either the publisher or the vendor, or both of them, do not pursue that purpose. Overall, the TCFs standardized matching and checking procedure helps to ensure that a legal basis exists for a specified, explicit and legitimate purpose wherever data flows. 7.5.2 Facilitating Checking Permission for Data Transfer Between Vendors In this section, we discuss the case where a vendor transfers data to another vendor. Checking the permission to process and transfer data is more straightforward for a vendor-to-vendor case than a publisher-to-vendor case. A vendor cannot use restrictions to adjust the legal basis for another vendor but only accepts whatever is disclosed in the GVL and stored in the TC string. Hence, a vendor can be in one of three states: (1) has user permission to process and transfer data (accept consent or accept legitimate interest), (2) does not have user permission to process and transfer data (deny consent or deny legitimate interest), or (3) does not pursue the purpose. Figure 20: Outcomes of States of Two Vendors When a Vendor Transfers Data to another Vendor Figure 20 summarizes the outcomes of data transfer between vendors. A vendor can only transfer personal data to another vendor if both vendors have the users permissions, captured by the green cell. The cells in red depict a failed deal to transfer data because at least one of the vendors lacks user permission to process data for the purpose. The cells in grey represent no deal as at least one of the vendors does not pursue the purpose with user data. 7.6 Main Takeaways The main takeaways from Section 7 are: A firm goes through three steps when getting permission for data processing, in order to supply a legal basis: (1) specifying purposes for data processing, (2) asking for and storing permission for the specified purposes, (3) checking permission for data transfer. The online advertising industry faces challenges for each of the three steps involved in getting permission for processing of personal data. The TCF is an industry initiative launched by IAB Europe, intending to tackle the challenges involved in getting permission for data processing by building up a standard for all participants to follow. TCF creates a uniform specification of purposes for data processing, shared by all participants, to prevent misunderstanding and help firms communicate conveniently with users and other firms. The TCF provides a Global Vendor List (GVL) to help vendors disclose their purposes, and publishers centralize and manage permission on behalf of their partner vendors. The TCF created the Transparency Consent string (TC string) to store, update and exchange a users permission in a standardized way. The TCF provides no warranty for the GDPR compliance. Moreover, even with the help of the TCF, the procedure to handle and check permission remains complicated. "],["empirical-examination-of-the-complexity-of-getting-permission-for-data-processing.html", "Section 8 Empirical Examination of the Complexity of Getting Permission for Data Processing", " Section 8 Empirical Examination of the Complexity of Getting Permission for Data Processing "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
